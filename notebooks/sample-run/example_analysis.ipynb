{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>VegMapper</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">License Terms\n",
    "\n",
    "Copyright (c) 2019, California Institute of Technology (\"Caltech\").  U.S. Government sponsorship acknowledged.\n",
    "\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "* Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
    "* Redistributions must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "* Neither the name of Caltech nor its operating division, the Jet Propulsion Laboratory, nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in Python libraries\n",
    "import ipywidgets as ipw\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up Python/R dual functionality for notebook\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#initialize R cell and load in necessary libraries\n",
    "library(rgdal)\n",
    "library(arm)\n",
    "library(gdalUtils)\n",
    "library(raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">User inputs:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "##### FILES #####\n",
    "#all GIS data in lat lon WGS84 unless specified\n",
    "#path to comma-delimited file, must have cols 'latitude', 'longitude', 'class'\n",
    "in_points = \"wwf_2018_clipped.csv\"\n",
    "\n",
    "#remote sensing stack in ENVI flat binary format, get stack info\n",
    "in_stack =  \"indo_stack_nov_2018_clipped\"\n",
    "\n",
    "#path to output comma-delimited file, same as in_points with appended remote sensing values\n",
    "out_points =  \"wwf_2018_clipped_testPred.csv\"\n",
    "\n",
    "#name of the output map in ENVI flat binary format\n",
    "out_pred = \"op3_indo_nov_2018_clipped\"\n",
    "\n",
    "#name of output GeoTIFF\n",
    "out_tif = \"predSurface.tif\"\n",
    "\n",
    "#--------------------------------------------------------------#\n",
    "\n",
    "##### PARAMETERS #####\n",
    "buffer = 1\n",
    "hhBandIndex = 0 #NOTE: see Apply routine for information\n",
    "\n",
    "#treshold for logistic model; \n",
    "    #when probability is larger than this threshold, we say that oil palm is present\n",
    "threshold = 0.5\n",
    "\n",
    "#RUN: priors (variable order corresponds to order in which bands are read), currently Costa Rica\n",
    "    #sequence of prior values needs to match the sequence of stack_names below\n",
    "use_prior = TRUE\n",
    "prior_mean = c(0.06491638, -26.63132179, 0.05590800, -29.64091620)\n",
    "prior_scale = c(0.02038204, 7.58200324, 0.01686930, 8.73995422)\n",
    "prior_mean_int = 1.99274801\n",
    "prior_scale_int = 7.22600112\n",
    "\n",
    "#lower and upper bounds for posterior credible intervals\n",
    "lp = 0.025\n",
    "up = 0.975\n",
    "\n",
    "#--------------------------------------------------------------#\n",
    "\n",
    "##### BAND INFO #####\n",
    "stack_names = c(\"vcf\", \"c_rvi\", \"ndvi\", \"l_rvi_mosaic\") #desired bands from the in_stack (names should match source)\n",
    "    #NOTE: this is a DEVELOPER input and not a user input,\n",
    "    #      please do not change this unless you have been approved to do so\n",
    "bands = c(2,3,1,4) #index of each of the bands defined above (from in_stack)\n",
    "nodata = -9999 #NA value present in input bands: NEEDS TO BE A LIST OF NUMBERS IF NOT CONSISTENT ACROSS BANDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>EXTRACT</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Objective: read remote sensing values at training points. The cell below creates a function to get intensity values from stack and executes extract routine:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "getPixel= function(gdalObject, X, Y, buffer, ulX, ulY, cellSize, bands){\n",
    "    nrow = dim(gdalObject)[1]\n",
    "    ncol = dim(gdalObject)[2]\n",
    "    rowOffset = ((ulY-Y)/cellSize) - buffer\n",
    "    if(rowOffset<0 | (rowOffset+buffer+2) > nrow){\n",
    "        return(NA)\n",
    "    }\n",
    "    colOffset = ((X-ulX)/cellSize) - buffer\n",
    "    if(colOffset<0 | (colOffset+buffer+2) > ncol){\n",
    "        return(NA)\n",
    "    } \n",
    "    windowY = buffer+2\n",
    "    windowX = windowY\n",
    "    pixelValue = getRasterData(gdalObject, band=bands, offset=c(rowOffset, colOffset), region.dim=c(windowY, windowX))\n",
    "    return(pixelValue)\n",
    "}\n",
    "\n",
    "#stack information\n",
    "r_stack = stack(in_stack)\n",
    "res = xres(r_stack)\n",
    "r_extent = r_stack@extent\n",
    "ulX = r_extent@xmin\n",
    "ulY = r_extent@ymax\n",
    "# s_info = GDALinfo(in_stack) also works, lacks ulY\n",
    "\n",
    "#grab stack\n",
    "gdalObj = new(\"GDALDataset\", in_stack)\n",
    "\n",
    "#append remote sensing information to point table and write to cvs file\n",
    "inData <- read.csv(in_points, header=TRUE)\n",
    "numPoints <- nrow(inData)\n",
    "\n",
    "header <- c(colnames(inData), stack_names)\n",
    "write.table(x=t(header), file=out_points, append=FALSE, col.names=FALSE, row.names=FALSE, sep=\",\")\n",
    "\n",
    "print(\"Extracting values for...\")\n",
    "for(i in 1:numPoints){\n",
    "    allBands <- rep(NA, length(bands))\n",
    "    for (j in 1:length(bands)){\n",
    "        oneBand = getPixel(gdalObj, inData$longitude[i], inData$latitude[i], buffer, ulX, ulY, res, bands[j])\n",
    "        w = which (oneBand == nodata[j])\n",
    "        oneBand[w]<-NA\n",
    "        allBands[j] = mean(oneBand, na.rm=TRUE)\n",
    "        if(i==1) print(stack_names[j])\n",
    "    }\n",
    "  mydata <- data.frame(t(as.vector(allBands)))\n",
    "  colnames(mydata) <- stack_names\n",
    "  newRow = cbind(inData[i,],mydata)\n",
    "  write.table(x=newRow, file=out_points, append=TRUE, col.names=FALSE, row.names=FALSE, sep=\",\") \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>RUN</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Objective: fit Bayesian model, calculate posteriors and confusion matrix. The cell below creates the model and executes the prediction, constructs a confusion matrix, calculates the prediction accuracy/posterior CI, calculates/builds posteriors for subsequent runs, and prints the result:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#ADDITIONAL INPUTS\n",
    "#columns of the predictor variables to be used in this model (taken from pred csv)\n",
    "    #column order indicated here is vcf, c_rvi, ndvi, l_rvi_mosaic, matching the priors above\n",
    "index = c(13,14,15,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#impute missing values by variable means\n",
    "data = read.csv(out_points)\n",
    "for (i in which(sapply(data, is.numeric))) {\n",
    "    for (j in which(is.na(data[, i]))) {\n",
    "        data[j, i] <- mean(data[data[, \"my_class\"] == data[j, \"my_class\"], i],  na.rm = TRUE)\n",
    "    }\n",
    "}\n",
    "\n",
    "#true_label: 1 for oil_palm and 0 for non oil_palm\n",
    "true_label = 1*(data$my_class == 'oil_palm') #EDIT: why this --> http://127.0.0.1:54098/notebooks/sample-run/example_analysis.ipynb\n",
    "\n",
    "#transform interested variables into a matrix which would be used\n",
    "x = as.matrix(data[, index])\n",
    "all_names = names(data)\n",
    "stack_names = all_names[index]\n",
    "colnames(x) = stack_names\n",
    "\n",
    "#build model by incorporating those variables\n",
    "formula = as.formula(paste(\"true_label ~ \", paste(stack_names, collapse=\"+\"),sep = \"\"))\n",
    "use_data = as.data.frame(cbind(x, true_label))\n",
    "\n",
    "#to specify prior\n",
    "#if noninformative prior, use prior.mean=apply(x, 2, mean), prior.scale=Inf, prior.df=Inf\n",
    "#if having a prior, set prior.mean=c(....), prior.scale=c(.....)\n",
    "#length of prior mean and prior scale should be equal to the number of predictors\n",
    "if(! use_prior){\n",
    "    model = bayesglm(formula, data=use_data, family=binomial(link='logit'), prior.mean=apply(x, 2, mean), prior.scale=Inf, scale=FALSE)\n",
    "}\n",
    "if(use_prior){\n",
    "    model = bayesglm(formula, data=use_data, family=binomial(link='logit'), \n",
    "                    prior.mean=prior_mean,\n",
    "                    prior.scale=prior_scale,\n",
    "                    prior.mean.for.intercept=prior_mean_int,\n",
    "                    prior.scale.for.intercept=prior_scale_int,\n",
    "            scale = FALSE)\n",
    "}\n",
    "\n",
    "#oil_palm prediction\n",
    "class_prediction = 1*(model$fitted.values >= threshold) #if the fitted value is above the threshold, value is changed to binary 1\n",
    "print(class_prediction)\n",
    "\n",
    "#used instead of na.remove to get rid of NA values in 2018 validation dataset\n",
    "true_label = true_label[!is.na(true_label)]\n",
    "\n",
    "#generate confusion matrix\n",
    "bayesian_conf_matrix = matrix(0,2,2)\n",
    "bayesian_conf_matrix[1,1] = sum(class_prediction + true_label == 0)\n",
    "bayesian_conf_matrix[2,2] = sum(class_prediction + true_label == 2)\n",
    "bayesian_conf_matrix[1,2] = sum((class_prediction == 0) & (true_label == 1))\n",
    "bayesian_conf_matrix[2,1] = sum((class_prediction == 1) & (true_label == 0))\n",
    "rownames(bayesian_conf_matrix) = c(\"Predicted non-oil-palm\", \"Predicted oil-palm\")\n",
    "colnames(bayesian_conf_matrix) = c(\"Actual non-oil-palm\", \"Actual oil-palm\")\n",
    "print(bayesian_conf_matrix)\n",
    "\n",
    "#overall accuracy of model\n",
    "accu_bayes = sum(class_prediction == true_label) / nrow(data)\n",
    "print(\"Overall accuracy:\")\n",
    "print(accu_bayes)\n",
    "\n",
    "#EDIT: push values to Python and use numpy/matplotlib to display matrix\n",
    "\n",
    "# approach posterior distributions of coefficients\n",
    "# specify number of draws \n",
    "num_draw = 2000\n",
    "post_dist = sim(model, n.sims=num_draw)\n",
    "coef_matrix = coef(post_dist)\n",
    "\n",
    "# calculate posterior credible intervals for coefficients\n",
    "posterior_ci_coef = matrix(NA, ncol(x)+1, 2)\n",
    "for (i in 1:(ncol(x)+1)){\n",
    "    posterior_ci_coef[i, ] = unname(quantile(coef_matrix[, i], probs=c(lp, up), na.rm=TRUE))\n",
    "}\n",
    "\n",
    "# calculate posterior credible intervals for every data point\n",
    "posterior_ci_data = matrix(NA, nrow(x), 2)\n",
    "for(i in 1:nrow(x)){\n",
    "    temp = as.numeric()\n",
    "    for(j in 1:num_draw){\n",
    "        temp[j] = 1 / (1 + exp(-coef_matrix[j, 1] - sum(coef_matrix[j, 2:(length(index)+1)] * x[i, ])))\n",
    "    }\n",
    "    posterior_ci_data[i, ] = unname(quantile(temp, probs=c(lp, up), na.rm=TRUE))\n",
    "}\n",
    "\n",
    "# build posterior objects for next run\n",
    "posterior_mean = model$coefficients\n",
    "posterior_scale = apply(coef(post_dist), 2, sd)\n",
    "\n",
    "#print the posteriors, store them for later\n",
    "#EDIT: not sure if this works with combinations of other stack variables than current build (need to test in future)\n",
    "posterior_mean\n",
    "intercept = posterior_mean[[\"(Intercept)\"]]\n",
    "numVars = length(posterior_mean)\n",
    "posteriors = posterior_mean[2:numVars] #EDIT: does this need to be transformed into c() variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>APPLY</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Objective: apply model fits to calculate OP3 for the area covered by the data stack. OP3 = oil palm probability presence, ranging between 0-1. The cell below applies the model to the stack and executes the predictive analysis, outputting the prediction surface in GeoTIFF and ENVI binary formats:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#generate dummy for Docker\n",
    "    #only use env variables if creation fails (will normally return NULL but still create object)\n",
    "# Sys.setenv(PROJ_LIB=\"/usr/bin/proj/\")\n",
    "# Sys.getenv(\"PROJ_LIB\")\n",
    "#dummy corresponds to one band from the original stack, used to save your output prediction map \n",
    "in_dummy = \"temp_dummy\"\n",
    "gdal_translate(src_dataset=in_stack, dst_dataset=in_dummy, of=\"ENVI\", b=1)\n",
    "\n",
    "#create GIS objects\n",
    "gdalObjStack = new(\"GDALDataset\", in_stack)\n",
    "gdalObjDummy = new(\"GDALDataset\", in_dummy)\n",
    "rasterWidth = ncol(gdalObjStack)\n",
    "rasterRows = nrow(gdalObjStack)\n",
    "\n",
    "#calculate prediction for each pixel and save\n",
    "print(\"Checking a few values...\")\n",
    "for(i in 1:rasterRows){\n",
    "    oneRasterLine = getRasterData(gdalObjStack, offset=c(i-1,0), region.dim=c(1, rasterWidth))\n",
    "    hhBand = hhBandIndex #PREVIOUSLY: which(bandNames == \"alos2_hh\")\n",
    "                         #NOTE: previous value was 0, bandNames/modelBands was removed for redundancy,\n",
    "                         #      the above code has not been tested yet\n",
    "    pred = rep(-9999, rasterWidth)\n",
    "    for(j in 1:rasterWidth){\n",
    "        #hh = (20*log10(oneRasterLine[j, 1, hhBand])) -83\n",
    "        hh = oneRasterLine[j, 1, hhBand] #gets hh value at each of the pixels\n",
    "        #open water mask\n",
    "        #if(is.na(hh) | hh < -20){ \n",
    "        #pred[j] = 0\n",
    "        #} \n",
    "        #else{\n",
    "            #select bands\n",
    "            selectBands = oneRasterLine[j, 1, bands] #EDITED: changed modelBands to bands\n",
    "            z = (intercept + sum(posteriors * selectBands))\n",
    "            pred[j] = exp(z)/(1+ exp(z))\n",
    "            #z = (intercept + sum(posteriors * scaledBands))\n",
    "            #pred[j] = exp(z)/(1+ exp(z))\n",
    "            if ((i/100 == i%/%100) & j == 1000) print(z) #reality check on the model fits\n",
    "        #}\n",
    "    }\n",
    "    #write one row to file\n",
    "    putRasterData(gdalObjDummy, pred, offset=c(i-1, 0)) #place predicted line in raster into dummy\n",
    "}\n",
    "saveDataset(gdalObjDummy, out_pred)\n",
    "\n",
    "#convert to GeoTiff\n",
    "gdal_translate(src_dataset=out_pred, dst_dataset=out_tif, of=\"GTiff\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}