{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>VegMapper</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">License Terms\n",
    "\n",
    "Copyright (c) 2019, California Institute of Technology (\"Caltech\").  U.S. Government sponsorship acknowledged.\n",
    "\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "* Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
    "* Redistributions must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "* Neither the name of Caltech nor its operating division, the Jet Propulsion Laboratory, nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rpy2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bee06d43bd60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#set up Python/R dual functionality for notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rpy2.ipython'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2285\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2287\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2288\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-65>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rpy2'"
     ]
    }
   ],
   "source": [
    "#set up Python/R dual functionality for notebook\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#initialize R cell and load in necessary libraries\n",
    "library(rgdal)\n",
    "library(arm)\n",
    "library(gdalUtils)\n",
    "library(raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">User inputs:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "##### FILES #####\n",
    "#all GIS data in lat lon WGS84 unless specified\n",
    "#path to comma-delimited file, must have cols 'latitude', 'longitude', 'class'\n",
    "in_points = \"wwf_2018_clipped.csv\"\n",
    "\n",
    "#remote sensing stack in ENVI flat binary format, get stack info\n",
    "in_stack =  \"indo_stack_nov_2018_clipped\"\n",
    "\n",
    "#path to output comma-delimited file, same as in_points with appended remote sensing values\n",
    "out_points =  \"wwf_2018_clipped_testPred.csv\"\n",
    "\n",
    "#dummy corresponds to one band from the original stack, used to save your output prediction map \n",
    "in_dummy = \"dummy_indo_nov_2018_clipped\"\n",
    "\n",
    "#name of the output map in ENVI flat binary format\n",
    "out_pred = \"op3_indo_nov_2018_clipped\"\n",
    "\n",
    "#name of output GeoTIFF\n",
    "out_tif = \"predSurface.tif\"\n",
    "\n",
    "#--------------------------------------------------------------#\n",
    "\n",
    "##### PARAMETERS #####\n",
    "buffer = 1\n",
    "\n",
    "#treshold for logistic model; \n",
    "    #when probability is larger than this threshold, we say that oil palm is present\n",
    "threshold = 0.5\n",
    "\n",
    "#RUN: priors (variable order corresponds to order in which bands are read), currently Costa Rica\n",
    "use_prior = TRUE\n",
    "prior_mean = c(0.06491638, -26.63132179, 0.05590800, -29.64091620)\n",
    "prior_scale = c(0.02038204, 7.58200324, 0.01686930, 8.73995422)\n",
    "prior_mean_int = 1.99274801\n",
    "prior_scale_int = 7.22600112\n",
    "\n",
    "#lower and upper bounds for posterior credible intervals\n",
    "lp = 0.025\n",
    "up = 0.975\n",
    "\n",
    "#APPLY: model parameters from your site, obtained with run_OP3-G20.R\n",
    "    #the coefficients match the variable names above\n",
    "    #EDIT: Fix this and connect variables from previous step\n",
    "intercept =  7.77338858\n",
    "posteriors = c(0.06768467, -43.16767103, 0.03948285, -9.89497112)\n",
    "\n",
    "#--------------------------------------------------------------#\n",
    "\n",
    "##### BAND INFO #####\n",
    "bands = c(2,3,1,4)\n",
    "stack_names = c(\"vcf\", \"c_rvi\", \"ndvi\", \"l_rvi_mosaic\") #must be consistent with band names defined below\n",
    "\n",
    "nodata = -9999 #NA value present in input bands: NEEDS TO BE A LIST OF NUMBERS IF NOT CONSISTENT ACROSS BANDS\n",
    "\n",
    "#columns of the predictor variables to be used in this model (taken from pred csv)\n",
    "    #column order indicated here is vcf, c_rvi, ndvi, l_rvi_mosaic, matching the priors above\n",
    "index = c(13,14,15,16)\n",
    "    #EDIT: find column indices using names of columns\n",
    "\n",
    "#names for all the bands in your stack. \n",
    "bandNames = c('ndvi', 'vcf', 'c_rvi', 'lrvi', 'alpha', 'lambda', 'entropy', 'anisotropy', 'hh', 'mask', 'l_rvi_mosaic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>EXTRACT</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Read remote sensing values at training points.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Create function to get intensity values from stack, execute extract routine:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "getPixel= function(gdalObject, X, Y, buffer, ulX, ulY, cellSize, bands){\n",
    "    nrow = dim(gdalObject)[1]\n",
    "    ncol = dim(gdalObject)[2]\n",
    "    rowOffset = ((ulY-Y)/cellSize) - buffer\n",
    "    if(rowOffset<0 | (rowOffset+buffer+2) > nrow){\n",
    "        return(NA)\n",
    "    }\n",
    "    colOffset = ((X-ulX)/cellSize) - buffer\n",
    "    if(colOffset<0 | (colOffset+buffer+2) > ncol){\n",
    "        return(NA)\n",
    "    } \n",
    "    windowY = buffer+2\n",
    "    windowX = windowY\n",
    "    pixelValue = getRasterData(gdalObject, band=bands, offset=c(rowOffset, colOffset), region.dim=c(windowY, windowX))\n",
    "    return(pixelValue)\n",
    "}\n",
    "\n",
    "#stack information\n",
    "r_stack = stack(in_stack)\n",
    "res = xres(r_stack)\n",
    "r_extent = r_stack@extent\n",
    "ulX = r_extent@xmin\n",
    "ulY = r_extent@ymax\n",
    "# s_info = GDALinfo(in_stack) also works, lacks ulY\n",
    "\n",
    "#grab stack\n",
    "gdalObj = new(\"GDALDataset\", in_stack)\n",
    "\n",
    "#append remote sensing information to point table and write to cvs file\n",
    "inData <- read.csv(in_points, header=TRUE)\n",
    "numPoints <- nrow(inData)\n",
    "\n",
    "header <- c(colnames(inData), stack_names)\n",
    "write.table(x=t(header), file=out_points, append=FALSE, col.names=FALSE, row.names=FALSE, sep=\",\")\n",
    "\n",
    "print(\"Extracting values for...\")\n",
    "for(i in 1:numPoints){\n",
    "    allBands <- rep(NA, length(bands))\n",
    "    for (j in 1:length(bands)){\n",
    "        oneBand = getPixel(gdalObj, inData$longitude[i], inData$latitude[i], buffer, ulX, ulY, res, bands[j])\n",
    "        w = which (oneBand == nodata[j])\n",
    "        oneBand[w]<-NA\n",
    "        allBands[j] = mean(oneBand, na.rm=TRUE)\n",
    "        if(i==1) print(stack_names[j])\n",
    "    }\n",
    "  mydata <- data.frame(t(as.vector(allBands)))\n",
    "  colnames(mydata) <- stack_names\n",
    "  newRow = cbind(inData[i,],mydata)\n",
    "  write.table(x=newRow, file=out_points, append=TRUE, col.names=FALSE, row.names=FALSE, sep=\",\") \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>RUN</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Fit Bayesian model, calculate posteriors and confusion matrix.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Create model and execute prediction:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#impute missing values by variable means\n",
    "data = read.csv(out_points)\n",
    "for (i in which(sapply(data, is.numeric))) {\n",
    "    for (j in which(is.na(data[, i]))) {\n",
    "        data[j, i] <- mean(data[data[, \"my_class\"] == data[j, \"my_class\"], i],  na.rm = TRUE)\n",
    "    }\n",
    "}\n",
    "\n",
    "#true_label: 1 for oil_palm and 0 for non oil_palm\n",
    "true_label = 1*(data$my_class == 'oil_palm')\n",
    "\n",
    "#transform interested variables into a matrix which would be used\n",
    "x = as.matrix(data[, index])\n",
    "all_names = names(data)\n",
    "stack_names = all_names[index]\n",
    "colnames(x) = stack_names\n",
    "\n",
    "#build model by incorporating those variables\n",
    "formula = as.formula(paste(\"true_label ~ \", paste(stack_names, collapse=\"+\"),sep = \"\"))\n",
    "use_data = as.data.frame(cbind(x, true_label))\n",
    "\n",
    "#to specify prior\n",
    "#if noninformative prior, use prior.mean=apply(x, 2, mean), prior.scale=Inf, prior.df=Inf\n",
    "#if having a prior, set prior.mean=c(....), prior.scale=c(.....)\n",
    "#length of prior mean and prior scale should be equal to the number of predictors\n",
    "if(! use_prior){\n",
    "    model = bayesglm(formula, data=use_data, family=binomial(link='logit'), prior.mean=apply(x, 2, mean), prior.scale=Inf, scale=FALSE)\n",
    "}\n",
    "if(use_prior){\n",
    "    model = bayesglm(formula, data=use_data, family=binomial(link='logit'), \n",
    "                    prior.mean=prior_mean,\n",
    "                    prior.scale=prior_scale,\n",
    "                    prior.mean.for.intercept=prior_mean_int,\n",
    "                    prior.scale.for.intercept=prior_scale_int,\n",
    "            scale = FALSE)\n",
    "}\n",
    "\n",
    "#oil_palm prediction\n",
    "class_prediction = 1*(model$fitted.values >= threshold) #if the fitted value is above the threshold, value is changed to binary 1\n",
    "print(class_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Construct confusion matrix, calculate prediction accuracy, posterior CI, print result:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#used instead of na.remove to get rid of NA values in 2018 validation dataset\n",
    "true_label = true_label[!is.na(true_label)]\n",
    "\n",
    "#generate confusion matrix\n",
    "bayesian_conf_matrix = matrix(0,2,2)\n",
    "bayesian_conf_matrix[1,1] = sum(class_prediction + true_label == 0)\n",
    "bayesian_conf_matrix[2,2] = sum(class_prediction + true_label == 2)\n",
    "bayesian_conf_matrix[1,2] = sum((class_prediction == 0) & (true_label == 1))\n",
    "bayesian_conf_matrix[2,1] = sum((class_prediction == 1) & (true_label == 0))\n",
    "rownames(bayesian_conf_matrix) = c(\"Predicted non-oil-palm\", \"Predicted oil-palm\")\n",
    "colnames(bayesian_conf_matrix) = c(\"Actual non-oil-palm\", \"Actual oil-palm\")\n",
    "print(bayesian_conf_matrix)\n",
    "\n",
    "#overall accuracy of model\n",
    "accu_bayes = sum(class_prediction == true_label) / nrow(data)\n",
    "print(\"Overall accuracy:\")\n",
    "print(accu_bayes)\n",
    "\n",
    "#EDIT: push values to Python and use numpy/matplotlib to display matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Calculate/build posteriors for subsequent runs, print result:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# approach posterior distributions of coefficients\n",
    "# specify number of draws \n",
    "num_draw = 2000\n",
    "post_dist = sim(model, n.sims=num_draw)\n",
    "coef_matrix = coef(post_dist)\n",
    "\n",
    "# calculate posterior credible intervals for coefficients\n",
    "posterior_ci_coef = matrix(NA, ncol(x)+1, 2)\n",
    "for (i in 1:(ncol(x)+1)){\n",
    "    posterior_ci_coef[i, ] = unname(quantile(coef_matrix[, i], probs=c(lp, up), na.rm=TRUE))\n",
    "}\n",
    "\n",
    "# calculate posterior credible intervals for every data point\n",
    "posterior_ci_data = matrix(NA, nrow(x), 2)\n",
    "for(i in 1:nrow(x)){\n",
    "    temp = as.numeric()\n",
    "    for(j in 1:num_draw){\n",
    "        temp[j] = 1 / (1 + exp(-coef_matrix[j, 1] - sum(coef_matrix[j, 2:(length(index)+1)] * x[i, ])))\n",
    "    }\n",
    "    posterior_ci_data[i, ] = unname(quantile(temp, probs=c(lp, up), na.rm=TRUE))\n",
    "}\n",
    "\n",
    "# build posterior objects for next run\n",
    "posterior_mean = model$coefficients\n",
    "posterior_scale = apply(coef(post_dist), 2, sd)\n",
    "\n",
    "#print the posteriors\n",
    "posterior_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>APPLY</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Apply model fits to calculate OP3 for the area covered by the data stack. OP3 = oil palm probability presence, ranging between 0-1.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Generate dummy:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#generate dummy for Docker\n",
    "    #only use env variables if creation fails (will normally return NULL but still create object)\n",
    "# Sys.setenv(PROJ_LIB=\"/usr/bin/proj/\")\n",
    "# Sys.getenv(\"PROJ_LIB\")\n",
    "gdal_translate(src_dataset=in_stack, dst_dataset=in_dummy, of=\"ENVI\", b=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Apply model to stack, execute predictive analysis:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#determine bands to use\n",
    "modelBands = rep(NA, length(stack_names))\n",
    "for(i in 1:length(modelBands)){\n",
    "    w = which(bandNames == stack_names[i])\n",
    "    modelBands[i] = w\n",
    "}\n",
    "\n",
    "#create GIS objects\n",
    "gdalObjStack = new(\"GDALDataset\", in_stack)\n",
    "gdalObjDummy = new(\"GDALDataset\", in_dummy)\n",
    "rasterWidth = ncol(gdalObjStack)\n",
    "rasterRows = nrow(gdalObjStack)\n",
    "\n",
    "#calculate prediction for each pixel and save\n",
    "print(\"Checking a few values...\")\n",
    "for(i in 1:rasterRows){\n",
    "    oneRasterLine = getRasterData(gdalObjStack, offset=c(i-1,0), region.dim=c(1, rasterWidth))\n",
    "    hhBand = which(bandNames == \"alos2_hh\")\n",
    "    pred = rep(-9999, rasterWidth)\n",
    "    for(j in 1:rasterWidth){\n",
    "        #hh = (20*log10(oneRasterLine[j, 1, hhBand])) -83\n",
    "        hh = oneRasterLine[j, 1, hhBand] #gets hh value at each of the pixels\n",
    "        #open water mask\n",
    "        #if(is.na(hh) | hh < -20){ \n",
    "        #pred[j] = 0\n",
    "        #} \n",
    "        #else{\n",
    "            #select bands\n",
    "            selectBands = oneRasterLine[j, 1, modelBands]\n",
    "            z = (intercept + sum(posteriors * selectBands))\n",
    "            pred[j] = exp(z)/(1+ exp(z))\n",
    "            #z = (intercept + sum(posteriors * scaledBands))\n",
    "            #pred[j] = exp(z)/(1+ exp(z))\n",
    "            if ((i/100 == i%/%100) & j == 1000) print(z) #reality check on the model fits\n",
    "        #}\n",
    "    }\n",
    "    #write one row to file\n",
    "    putRasterData(gdalObjDummy, pred, offset=c(i-1, 0)) #place predicted line in raster into dummy\n",
    "}\n",
    "saveDataset(gdalObjDummy, out_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Convert to GeoTiff:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "gdal_translate(src_dataset=out_pred, dst_dataset=out_tif, of=\"GTiff\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
