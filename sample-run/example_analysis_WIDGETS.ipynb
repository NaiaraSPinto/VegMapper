{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>VegMapper</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">License Terms\n",
    "\n",
    "Copyright (c) 2019, California Institute of Technology (\"Caltech\").  U.S. Government sponsorship acknowledged.\n",
    "\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "* Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
    "* Redistributions must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "* Neither the name of Caltech nor its operating division, the Jet Propulsion Laboratory, nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in Python libraries\n",
    "import ipywidgets as ipw\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up Python/R dual functionality for notebook\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#initialize R cell and load in necessary libraries\n",
    "library(rgdal)\n",
    "library(arm)\n",
    "library(gdalUtils)\n",
    "library(raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">User inputs:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "##### FILES #####\n",
    "printmd('<font face=\"Helvetica\" size=\"4\"><b>FILE INPUTS:<b>')\n",
    "#all GIS data in lat lon WGS84 unless specified\n",
    "#path to comma-delimited file, must have cols 'latitude', 'longitude', 'class'\n",
    "fc_in_points = FileChooser()\n",
    "fc_in_points.use_dir_icons = True\n",
    "fc_in_points.title = '<font face=\"Helvetica\" size=\"2\"><b>Please select the validation points (csv file):</b>'\n",
    "display(fc_in_points)\n",
    "\n",
    "#remote sensing stack in ENVI flat binary format, get stack info\n",
    "fc_in_stack = FileChooser()\n",
    "fc_in_stack.use_dir_icons = True\n",
    "fc_in_stack.title = '<font face=\"Helvetica\" size=\"2\"><b>Please select the remote sensing stack (NOT the .hdr file):</b>'\n",
    "display(fc_in_stack)\n",
    "\n",
    "#path to output comma-delimited file, same as in_points with appended remote sensing values\n",
    "printmd('<font face=\"Helvetica\" size=\"2\"><b>Name of output validation csv appended remote sensing values (please include .csv):<b>')\n",
    "printmd('<font face=\"Helvetica\" size=\"2\">NOTE: there is no need to press enter to confirm the name')\n",
    "name_out_points = ipw.Text(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description='File name:',\n",
    "    disabled=False\n",
    ")\n",
    "display(name_out_points)\n",
    "\n",
    "#name of the output map in ENVI flat binary format\n",
    "printmd('<font face=\"Helvetica\" size=\"2\"><b>Name of output map in ENVI flat binary format:<b>')\n",
    "printmd('<font face=\"Helvetica\" size=\"2\">NOTE: there is no need to press enter to confirm the name')\n",
    "name_out_pred = ipw.Text(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description='File name:',\n",
    "    disabled=False\n",
    ")\n",
    "display(name_out_pred)\n",
    "\n",
    "#name of output GeoTIFF\n",
    "printmd('<font face=\"Helvetica\" size=\"2\"><b>Name of output GeoTIFF (please include .tif):<b>')\n",
    "printmd('<font face=\"Helvetica\" size=\"2\">NOTE: there is no need to press enter to confirm the name')\n",
    "name_out_tif = ipw.Text(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description='File name:',\n",
    "    disabled=False\n",
    ")\n",
    "display(name_out_tif)\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------#\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "##### PARAMETERS #####\n",
    "printmd('<font face=\"Helvetica\" size=\"4\"><b>PARAMETER INPUTS:<b>')\n",
    "printmd('<font face=\"Helvetica\" size=\"2\">NOTE: when probability is larger than threshold, we say that oil palm is present')\n",
    "#buffer\n",
    "value_buffer = ipw.BoundedIntText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=5,\n",
    "    step=1,\n",
    "    description='# of cells:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "#threshold\n",
    "value_threshold = ipw.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description='Float:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    ")\n",
    "\n",
    "#prior\n",
    "status_use_prior = ipw.Checkbox(\n",
    "    value=False,\n",
    "    description='Use prior in model?',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "accordion = ipw.Accordion(children=[value_buffer, value_threshold, status_use_prior])\n",
    "accordion.set_title(0, 'Buffer size')\n",
    "accordion.set_title(1, 'Threshold for logistic model')\n",
    "accordion.set_title(2, 'Prior selection')\n",
    "display(accordion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Set inputs as variables:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_points = fc_in_points.selected_filename\n",
    "in_stack = fc_in_stack.selected_filename\n",
    "out_points = name_out_points.value\n",
    "out_pred = name_out_pred.value\n",
    "out_tif = name_out_tif.value\n",
    "buffer = value_buffer.value\n",
    "threshold = value_threshold.value\n",
    "use_prior = status_use_prior.value\n",
    "\n",
    "print('User file inputs: ','\\n', in_points, '\\n', in_stack, '\\n', out_points, '\\n', out_pred, '\\n', out_tif, '\\n', buffer, '\\n', threshold, '\\n', use_prior)\n",
    "#EDIT: could add exception handling here, other user input sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">Push file inputs to R:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%Rpush in_points in_stack out_points out_pred out_tif buffer threshold use_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#test push success\n",
    "push_file_variables = list(in_points, in_stack, out_points, out_pred, out_tif, buffer, threshold, use_prior)\n",
    "print(push_file_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Helvetica\" size=\"3\">TEMP: OTHER USER INPUTS W/O WIDGET:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "##### PARAMETERS #####\n",
    "#RUN: priors (variable order corresponds to order in which bands are read), currently Costa Rica\n",
    "prior_mean = c(0.06491638, -26.63132179, 0.05590800, -29.64091620)\n",
    "prior_scale = c(0.02038204, 7.58200324, 0.01686930, 8.73995422)\n",
    "prior_mean_int = 1.99274801\n",
    "prior_scale_int = 7.22600112\n",
    "\n",
    "#lower and upper bounds for posterior credible intervals\n",
    "lp = 0.025\n",
    "up = 0.975\n",
    "\n",
    "#--------------------------------------------------------------#\n",
    "\n",
    "##### BAND INFO #####\n",
    "bands = c(2,3,1,4)\n",
    "stack_names = c(\"vcf\", \"c_rvi\", \"ndvi\", \"l_rvi_mosaic\") #must be consistent with band names defined below\n",
    "\n",
    "nodata = -9999 #NA value present in input bands: NEEDS TO BE A LIST OF NUMBERS IF NOT CONSISTENT ACROSS BANDS\n",
    "\n",
    "#columns of the predictor variables to be used in this model (taken from pred csv)\n",
    "    #column order indicated here is vcf, c_rvi, ndvi, l_rvi_mosaic, matching the priors above\n",
    "index = c(13,14,15,16)\n",
    "    #EDIT: find column indices using names of columns\n",
    "\n",
    "#names for all the bands in your stack. \n",
    "bandNames = c('ndvi', 'vcf', 'c_rvi', 'lrvi', 'alpha', 'lambda', 'entropy', 'anisotropy', 'hh', 'mask', 'l_rvi_mosaic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>EXTRACT</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Objective: read remote sensing values at training points. The cell below creates a function to get intensity values from stack and executes extract routine:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "getPixel= function(gdalObject, X, Y, buffer, ulX, ulY, cellSize, bands){\n",
    "    nrow = dim(gdalObject)[1]\n",
    "    ncol = dim(gdalObject)[2]\n",
    "    rowOffset = ((ulY-Y)/cellSize) - buffer\n",
    "    if(rowOffset<0 | (rowOffset+buffer+2) > nrow){\n",
    "        return(NA)\n",
    "    }\n",
    "    colOffset = ((X-ulX)/cellSize) - buffer\n",
    "    if(colOffset<0 | (colOffset+buffer+2) > ncol){\n",
    "        return(NA)\n",
    "    } \n",
    "    windowY = buffer+2\n",
    "    windowX = windowY\n",
    "    pixelValue = getRasterData(gdalObject, band=bands, offset=c(rowOffset, colOffset), region.dim=c(windowY, windowX))\n",
    "    return(pixelValue)\n",
    "}\n",
    "\n",
    "#stack information\n",
    "r_stack = stack(in_stack)\n",
    "res = xres(r_stack)\n",
    "r_extent = r_stack@extent\n",
    "ulX = r_extent@xmin\n",
    "ulY = r_extent@ymax\n",
    "# s_info = GDALinfo(in_stack) also works, lacks ulY\n",
    "\n",
    "#grab stack\n",
    "gdalObj = new(\"GDALDataset\", in_stack)\n",
    "\n",
    "#append remote sensing information to point table and write to cvs file\n",
    "inData <- read.csv(in_points, header=TRUE)\n",
    "numPoints <- nrow(inData)\n",
    "\n",
    "header <- c(colnames(inData), stack_names)\n",
    "write.table(x=t(header), file=out_points, append=FALSE, col.names=FALSE, row.names=FALSE, sep=\",\")\n",
    "\n",
    "print(\"Extracting values for...\")\n",
    "for(i in 1:numPoints){\n",
    "    allBands <- rep(NA, length(bands))\n",
    "    for (j in 1:length(bands)){\n",
    "        oneBand = getPixel(gdalObj, inData$longitude[i], inData$latitude[i], buffer, ulX, ulY, res, bands[j])\n",
    "        w = which (oneBand == nodata[j])\n",
    "        oneBand[w]<-NA\n",
    "        allBands[j] = mean(oneBand, na.rm=TRUE)\n",
    "        if(i==1) print(stack_names[j])\n",
    "    }\n",
    "  mydata <- data.frame(t(as.vector(allBands)))\n",
    "  colnames(mydata) <- stack_names\n",
    "  newRow = cbind(inData[i,],mydata)\n",
    "  write.table(x=newRow, file=out_points, append=TRUE, col.names=FALSE, row.names=FALSE, sep=\",\") \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>RUN</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Objective: fit Bayesian model, calculate posteriors and confusion matrix. The cell below creates the model and executes the prediction, constructs a confusion matrix, calculates the prediction accuracy/posterior CI, calculates/builds posteriors for subsequent runs, and prints the result:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#impute missing values by variable means\n",
    "data = read.csv(out_points)\n",
    "for (i in which(sapply(data, is.numeric))) {\n",
    "    for (j in which(is.na(data[, i]))) {\n",
    "        data[j, i] <- mean(data[data[, \"my_class\"] == data[j, \"my_class\"], i],  na.rm = TRUE)\n",
    "    }\n",
    "}\n",
    "\n",
    "#true_label: 1 for oil_palm and 0 for non oil_palm\n",
    "true_label = 1*(data$my_class == 'oil_palm') #EDIT: why this --> http://127.0.0.1:54098/notebooks/sample-run/example_analysis.ipynb\n",
    "\n",
    "#transform interested variables into a matrix which would be used\n",
    "x = as.matrix(data[, index])\n",
    "all_names = names(data)\n",
    "stack_names = all_names[index]\n",
    "colnames(x) = stack_names\n",
    "\n",
    "#build model by incorporating those variables\n",
    "formula = as.formula(paste(\"true_label ~ \", paste(stack_names, collapse=\"+\"),sep = \"\"))\n",
    "use_data = as.data.frame(cbind(x, true_label))\n",
    "\n",
    "#to specify prior\n",
    "#if noninformative prior, use prior.mean=apply(x, 2, mean), prior.scale=Inf, prior.df=Inf\n",
    "#if having a prior, set prior.mean=c(....), prior.scale=c(.....)\n",
    "#length of prior mean and prior scale should be equal to the number of predictors\n",
    "if(! use_prior){\n",
    "    model = bayesglm(formula, data=use_data, family=binomial(link='logit'), prior.mean=apply(x, 2, mean), prior.scale=Inf, scale=FALSE)\n",
    "}\n",
    "if(use_prior){\n",
    "    model = bayesglm(formula, data=use_data, family=binomial(link='logit'), \n",
    "                    prior.mean=prior_mean,\n",
    "                    prior.scale=prior_scale,\n",
    "                    prior.mean.for.intercept=prior_mean_int,\n",
    "                    prior.scale.for.intercept=prior_scale_int,\n",
    "            scale = FALSE)\n",
    "}\n",
    "\n",
    "#oil_palm prediction\n",
    "class_prediction = 1*(model$fitted.values >= threshold) #if the fitted value is above the threshold, value is changed to binary 1\n",
    "print(class_prediction)\n",
    "\n",
    "#used instead of na.remove to get rid of NA values in 2018 validation dataset\n",
    "true_label = true_label[!is.na(true_label)]\n",
    "\n",
    "#generate confusion matrix\n",
    "bayesian_conf_matrix = matrix(0,2,2)\n",
    "bayesian_conf_matrix[1,1] = sum(class_prediction + true_label == 0)\n",
    "bayesian_conf_matrix[2,2] = sum(class_prediction + true_label == 2)\n",
    "bayesian_conf_matrix[1,2] = sum((class_prediction == 0) & (true_label == 1))\n",
    "bayesian_conf_matrix[2,1] = sum((class_prediction == 1) & (true_label == 0))\n",
    "rownames(bayesian_conf_matrix) = c(\"Predicted non-oil-palm\", \"Predicted oil-palm\")\n",
    "colnames(bayesian_conf_matrix) = c(\"Actual non-oil-palm\", \"Actual oil-palm\")\n",
    "print(bayesian_conf_matrix)\n",
    "\n",
    "#overall accuracy of model\n",
    "accu_bayes = sum(class_prediction == true_label) / nrow(data)\n",
    "print(\"Overall accuracy:\")\n",
    "print(accu_bayes)\n",
    "\n",
    "#EDIT: push values to Python and use numpy/matplotlib to display matrix\n",
    "\n",
    "# approach posterior distributions of coefficients\n",
    "# specify number of draws \n",
    "num_draw = 2000\n",
    "post_dist = sim(model, n.sims=num_draw)\n",
    "coef_matrix = coef(post_dist)\n",
    "\n",
    "# calculate posterior credible intervals for coefficients\n",
    "posterior_ci_coef = matrix(NA, ncol(x)+1, 2)\n",
    "for (i in 1:(ncol(x)+1)){\n",
    "    posterior_ci_coef[i, ] = unname(quantile(coef_matrix[, i], probs=c(lp, up), na.rm=TRUE))\n",
    "}\n",
    "\n",
    "# calculate posterior credible intervals for every data point\n",
    "posterior_ci_data = matrix(NA, nrow(x), 2)\n",
    "for(i in 1:nrow(x)){\n",
    "    temp = as.numeric()\n",
    "    for(j in 1:num_draw){\n",
    "        temp[j] = 1 / (1 + exp(-coef_matrix[j, 1] - sum(coef_matrix[j, 2:(length(index)+1)] * x[i, ])))\n",
    "    }\n",
    "    posterior_ci_data[i, ] = unname(quantile(temp, probs=c(lp, up), na.rm=TRUE))\n",
    "}\n",
    "\n",
    "# build posterior objects for next run\n",
    "posterior_mean = model$coefficients\n",
    "posterior_scale = apply(coef(post_dist), 2, sd)\n",
    "\n",
    "#print the posteriors, store them for later\n",
    "#EDIT: not sure if this works with combinations of other stack variables than current build (need to test in future)\n",
    "posterior_mean\n",
    "intercept = posterior_mean[[\"(Intercept)\"]]\n",
    "numVars = length(posterior_mean)\n",
    "posteriors = posterior_mean[2:numVars] #EDIT: does this need to be transformed into c() variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><br>\n",
    "<font face=\"Helvetica\" size=\"5\"><b>APPLY</b></font>\n",
    "<br><br>\n",
    "<font face=\"Helvetica\" size=\"3\">Objective: apply model fits to calculate OP3 for the area covered by the data stack. OP3 = oil palm probability presence, ranging between 0-1. The cell below applies the model to the stack and executes the predictive analysis, outputting the prediction surface in GeoTIFF and ENVI binary formats:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#generate dummy for Docker\n",
    "    #only use env variables if creation fails (will normally return NULL but still create object)\n",
    "# Sys.setenv(PROJ_LIB=\"/usr/bin/proj/\")\n",
    "# Sys.getenv(\"PROJ_LIB\")\n",
    "#dummy corresponds to one band from the original stack, used to save your output prediction map \n",
    "in_dummy = \"temp_dummy\"\n",
    "gdal_translate(src_dataset=in_stack, dst_dataset=in_dummy, of=\"ENVI\", b=1)\n",
    "\n",
    "#determine bands to use\n",
    "modelBands = rep(NA, length(stack_names))\n",
    "for(i in 1:length(modelBands)){\n",
    "    w = which(bandNames == stack_names[i])\n",
    "    modelBands[i] = w\n",
    "}\n",
    "\n",
    "#create GIS objects\n",
    "gdalObjStack = new(\"GDALDataset\", in_stack)\n",
    "gdalObjDummy = new(\"GDALDataset\", in_dummy)\n",
    "rasterWidth = ncol(gdalObjStack)\n",
    "rasterRows = nrow(gdalObjStack)\n",
    "\n",
    "#calculate prediction for each pixel and save\n",
    "print(\"Checking a few values...\")\n",
    "for(i in 1:rasterRows){\n",
    "    oneRasterLine = getRasterData(gdalObjStack, offset=c(i-1,0), region.dim=c(1, rasterWidth))\n",
    "    hhBand = which(bandNames == \"alos2_hh\")\n",
    "    pred = rep(-9999, rasterWidth)\n",
    "    for(j in 1:rasterWidth){\n",
    "        #hh = (20*log10(oneRasterLine[j, 1, hhBand])) -83\n",
    "        hh = oneRasterLine[j, 1, hhBand] #gets hh value at each of the pixels\n",
    "        #open water mask\n",
    "        #if(is.na(hh) | hh < -20){ \n",
    "        #pred[j] = 0\n",
    "        #} \n",
    "        #else{\n",
    "            #select bands\n",
    "            selectBands = oneRasterLine[j, 1, modelBands]\n",
    "            z = (intercept + sum(posteriors * selectBands))\n",
    "            pred[j] = exp(z)/(1+ exp(z))\n",
    "            #z = (intercept + sum(posteriors * scaledBands))\n",
    "            #pred[j] = exp(z)/(1+ exp(z))\n",
    "            if ((i/100 == i%/%100) & j == 1000) print(z) #reality check on the model fits\n",
    "        #}\n",
    "    }\n",
    "    #write one row to file\n",
    "    putRasterData(gdalObjDummy, pred, offset=c(i-1, 0)) #place predicted line in raster into dummy\n",
    "}\n",
    "saveDataset(gdalObjDummy, out_pred)\n",
    "\n",
    "#convert to GeoTiff\n",
    "gdal_translate(src_dataset=out_pred, dst_dataset=out_tif, of=\"GTiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
