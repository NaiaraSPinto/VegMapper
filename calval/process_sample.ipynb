{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agroimpacts/VegMapper/blob/dev-calval-simplify/calval/process_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c515862",
      "metadata": {
        "id": "3c515862"
      },
      "source": [
        "# Creating a single training/validation/test set from multiple Collect Earth projects\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c59e929",
      "metadata": {
        "id": "0c59e929"
      },
      "source": [
        "### Table of Contents\n",
        "\n",
        "* [Overview](#overview)\n",
        "* [Set-up](#setup)\n",
        "* [Sample preparation](#sample-prep)\n",
        "    * [Read-in, reshape, and recode](#reshape-recode)\n",
        "    * [Simplify the classes](#simplify)\n",
        "    * [Calculate sample agreement](#agreement)\n",
        "* [Split the dataset](#split)\n",
        "    * [Combine and convert to spatial](#combine)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af718f4a",
      "metadata": {
        "id": "af718f4a"
      },
      "source": [
        "## Overview <a class=\"anchor\" id=\"overview\"></a>\n",
        "This notebook demonstrates how several Collect Earth Online projects can be:\n",
        "\n",
        "1. Provide functionality to check the structure and validity of user input for modeling; Yet, users are responsible for providing data in good format.\n",
        "2. Re-code the class values and rename the column names.\n",
        "2. Merged into a single dataset that provide a single label for each sample point and an estimate of label uncertainty;\n",
        "3. Split into training, validation, and test (or map reference) samples.\n",
        "\n",
        "The example data that can be used for this notebook, if you don't bring your own, are the results of three Collect Earth Online projects that were captured over the Department of Ucayali, Peru. They are in the VegMapper repo under the calval/data folder. Each project csv represents the efforts of an individual (or group of individuals working in the same project) to label 1350 points, classifying each into 1 of 4 classes: not oil palm; young oil palm; mature oil palm;  unsure. The datasets preserve all the information from these projects, although user email addresses were anonymized.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e56ab0",
      "metadata": {
        "id": "34e56ab0"
      },
      "source": [
        "## Sample preparation <a class=\"anchor\" id=\"sample-prep\"></a>\n",
        "Load packages, setup configuations, define a helper function..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title (RUN) Install packages\n",
        "%%capture\n",
        "!pipe install folium"
      ],
      "metadata": {
        "cellView": "form",
        "id": "91eibcwU8EUD"
      },
      "id": "91eibcwU8EUD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0968b28e",
      "metadata": {
        "id": "0968b28e",
        "tags": [],
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# from label_utils import load_csv, subset_cols, rename_cols,\\\n",
        "#     check_exclusive, recode, combine_labelers, get_mode_and_occurence\n",
        "\n",
        "#@title (RUN) Setup code\n",
        "## Mount Drive\n",
        "from google.colab import drive\n",
        "root = '/content/gdrive'\n",
        "drive.mount(root)\n",
        "\n",
        "## Clone and/or update VegMapper\n",
        "import os\n",
        "# from datetime import datetime as dt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "repo_path = f\"{root}/MyDrive/repos\"\n",
        "clone_path = 'https://github.com/agroimpacts/VegMapper.git'\n",
        "if not os.path.exists(repo_path):\n",
        "    print(f\"Making {repo_path}\")\n",
        "    os.makedirs(repo_path, exist_ok=True)\n",
        "\n",
        "if not os.path.exists(f\"{repo_path}/VegMapper\"):\n",
        "    !git -C \"{repo_path}\" clone \"{clone_path}\"\n",
        "else:\n",
        "    !git -C \"{repo_path}/VegMapper\" pull\n",
        "\n",
        "os.chdir(f\"{repo_path}/VegMapper\")\n",
        "\n",
        "# Import sample_utils function\n",
        "from vegmapper.calval.label_utils import *\n",
        "from functools import partial\n",
        "import folium"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load the CSV files, you only need to open the directory on the left panel of your Colab notebook. Then, navigate to the directory where you have the files, click on the three dots menue to the right of the file names, and select 'Copy Path.' Finally, paste the path in the box below."
      ],
      "metadata": {
        "id": "V5ck87okI3TH"
      },
      "id": "V5ck87okI3TH"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title (RUN) Load CEO Project CSVs\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        num_users = int(input(\"Enter the number of CEO projects (The number of CEO projects must be more than 2): \"))\n",
        "        if num_users < 2:\n",
        "            print(\"The number of CEO projects must be at least 2.\")\n",
        "        else:\n",
        "            break\n",
        "    except ValueError:\n",
        "        print(\"Invalid input. Please enter a valid number.\")\n",
        "\n",
        "# Initialize the list to store file paths\n",
        "fs = []\n",
        "\n",
        "# Loop to input file paths for each user\n",
        "for i in range(num_users):\n",
        "    while True:\n",
        "        file_path = input(f\"Enter the CSV file name for user {i+1}: \")\n",
        "        if not file_path:\n",
        "            print(\"File name cannot be empty.\")\n",
        "        else:\n",
        "            fs.append(file_path)\n",
        "            break"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d0IrPNN97mV-"
      },
      "id": "d0IrPNN97mV-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title (RUN) Check that project \"plot_id\"s match\n",
        "dataframes = []\n",
        "\n",
        "# Read each CSV file into a DataFrame and store them in the list\n",
        "for csv_file in fs:\n",
        "    df = pd.read_csv(csv_file)\n",
        "    dataframes.append(df)\n",
        "\n",
        "# Check if 'plot_id' column values are the same in all DataFrames\n",
        "plot_id_values = [df['plot_id'] for df in dataframes]\n",
        "\n",
        "# Assuming all DataFrames have the same number of rows, you can use the `all`\n",
        "# function\n",
        "if all(plot_id.equals(plot_id_values[0]) for plot_id in plot_id_values):\n",
        "    print(\"'plot_id' values are match in all CEO projects\")\n",
        "else:\n",
        "    print(\"'plot_id' values must be same in all CEO projects\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ss6JE906bYMG"
      },
      "id": "ss6JE906bYMG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: it is important to make sure that the CEO project files come from the same project, such each plot_id represents the same location. It is theoretically possible that 2 or more projects could have the same numbers of plots and plot_id numbers, but each plot_id represents a different location, in which case the results here will not be valid."
      ],
      "metadata": {
        "id": "yDZ1npQs1l2y"
      },
      "id": "yDZ1npQs1l2y"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title (RUN) Define and the class column names\n",
        "df = pd.read_csv(fs[0])\n",
        "\n",
        "print(\"\\nColumn Names and Indices:\")\n",
        "for i, column in enumerate(df.columns):\n",
        "    print(f\"{i}: {column}\")\n",
        "\n",
        "new_col_names_input = input(\n",
        "    \"Enter the names you would like to represent the presence and absence \\n\"\\\n",
        "    \"classes and any class you use to represent uncertainty, e.g. Presence,\\n\"\\\n",
        "    \"Absence, Unsure. Separate each with a comma: \"\n",
        ")\n",
        "new_col_names = [name.strip() for name in new_col_names_input.split(',')]\n",
        "new_col_names\n",
        "\n",
        "presence_columns_input = input(\n",
        "    f\"Enter column indices to change to '{new_col_names[0]}'\"\\\n",
        "    \" (separate with comma): \"\n",
        ")\n",
        "presence_columns = [\n",
        "    index.strip() for index in presence_columns_input.split(',')\n",
        "]\n",
        "\n",
        "absence_columns_input = input(\n",
        "    f\"Enter column indices to change to '{new_col_names[1]}'\"\\\n",
        "    \" (separate with comma): \"\n",
        ")\n",
        "absence_columns = [index.strip() for index in absence_columns_input.split(',')]\n",
        "\n",
        "not_sure_columns_input = input(\n",
        "    f\"Enter column indices to change to '{new_col_names[2]}'\"\\\n",
        "     \" (separate with comma): \"\n",
        ")\n",
        "not_sure_columns = [\n",
        "    index.strip() for index in not_sure_columns_input.split(',')\n",
        "]\n",
        "\n",
        "rename_dict = {\n",
        "    \"plot_id\": \"Point_ID\",\n",
        "    \"pl_cluster\": \"Clust\",\n",
        "    \"center_lat\": \"Lat\",\n",
        "    \"center_lon\": \"Lon\"\n",
        "}\n",
        "for i, column in enumerate(df.columns):\n",
        "    if str(i) in presence_columns:\n",
        "        rename_dict[column] = new_col_names[0]\n",
        "    elif str(i) in absence_columns:\n",
        "        rename_dict[column] = new_col_names[1]\n",
        "    elif str(i) in not_sure_columns:\n",
        "        rename_dict[column] = new_col_names[2]\n",
        "\n",
        "print(rename_dict)\n",
        "print(new_col_names)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UNjyBGkHfUiJ"
      },
      "id": "UNjyBGkHfUiJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Provide a numerical code presence (e.g. 1), absence (e.g. 0) and unsure (e.g. 2, if present)\n",
        "recode_dict = {}\n",
        "\n",
        "# Iterate through new_col_names and get user input for values\n",
        "for column_name in new_col_names:\n",
        "    arbitrary_number = int(input(f\"Enter a number for the '{column_name}' category: \"))\n",
        "    recode_dict[column_name] = arbitrary_number\n",
        "\n",
        "print(\"Updated recode_dict:\")\n",
        "print(recode_dict)"
      ],
      "metadata": {
        "id": "5De1DlmtWGoA",
        "cellView": "form"
      },
      "id": "5De1DlmtWGoA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "88b2fe77-3b6e-4b03-aa71-67529e0993ab",
      "metadata": {
        "id": "88b2fe77-3b6e-4b03-aa71-67529e0993ab"
      },
      "source": [
        "### Read-in, reshape, and recode classes <a class=\"anchor\" id=\"reshape-recode\"></a>\n",
        "The first step was to combine the three datasets into a single dataset, with the columns from each of the three CEO projects, and to recode the four classes into a single column with values 0 (absence),  1 (presence), and 2 (unsure, assuming this category exists). At this step, there will be one column per CEO project. Each column contains the recoded classes (note the renaming of the columns is done in the next code chunk)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title (RUN) Process and combine csvs\n",
        "label_name = \"labeler\"\n",
        "\n",
        "# Define a partial function with fixed arguments\n",
        "process_csv_partial = partial(process_csv, rename_dict=rename_dict,\n",
        "                              recode_dict=recode_dict,\n",
        "                              new_col_names=new_col_names)\n",
        "\n",
        "# Process ceo-survey-users one by one\n",
        "dats = list(map(process_csv_partial, fs))\n",
        "\n",
        "# Combine three datasets into one\n",
        "combined = combine_labelers(dats, by=[\"Point_ID\", \"Clust\"],\n",
        "                            label_name=label_name, fs=fs)\n",
        "combined_pl = combined.drop(columns=['Clust'])\n",
        "combined_pl.head()"
      ],
      "metadata": {
        "id": "fFPKSi2HA7ti",
        "cellView": "form"
      },
      "id": "fFPKSi2HA7ti",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "94baf77b",
      "metadata": {
        "id": "94baf77b"
      },
      "source": [
        "### Calculate sample agreement <a class=\"anchor\" id=\"agreement\"></a>\n",
        "The next step was to calculate some agreement metrics across the three groups' samples. The primary approach was to calculate the proportion of labelling teams that selected the modal class. Since there were just three teams in this example, values were either 0.333, 0.667, 1. This agreement was calculated across for both the original classification scheme and the simplifed scheme, with columns `agree` and `agree2` providing the respective proportions for each observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a845bbb",
      "metadata": {
        "id": "5a845bbb",
        "tags": [],
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) Agreement mode\n",
        "\n",
        "num_labelers = len(fs)\n",
        "labels = []\n",
        "\n",
        "for i in range(1, num_labelers + 1):\n",
        "    file_name = os.path.splitext(os.path.basename(fs[i-1]))[0]\n",
        "    labels.append(file_name)\n",
        "\n",
        "combined[['mode', 'mode_agreement']] = combined[labels].apply(get_mode_and_occurence, axis=1, result_type='expand')\n",
        "pd.set_option('display.max_rows', None)\n",
        "#print(combined)\n",
        "\n",
        "# we can set the mode to -9999 if there is no agreement (mode_freq = 1/num_labelers)\n",
        "combined.loc[combined['mode_agreement'] <= 1/3, 'mode'] = -9999\n",
        "\n",
        "combined = combined.drop(combined[combined['mode'] == -9999].index)\n",
        "print(f\"Combined project has {combined.shape[0]} rows, {combined.shape[1]}\"\\\n",
        "      \"columns\")\n",
        "\n",
        "combined_pl2 = combined.drop(columns=['Clust'])\n",
        "\n",
        "combined_pl2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6ab33e9",
      "metadata": {
        "id": "c6ab33e9"
      },
      "source": [
        "We can then calculate the average agreement per sample to get a sense of the uncertainty in labels for each class, for all 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3cbab14",
      "metadata": {
        "id": "d3cbab14",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) Calculate average agreement per sample\n",
        "agreement = combined.groupby(\"mode\").mean()\n",
        "agreement = agreement.rename(columns={\"mode_agreement\": \"mean agreement\"})\n",
        "print(agreement[['mean agreement']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b5b0926",
      "metadata": {
        "id": "5b5b0926"
      },
      "source": [
        "## Split the dataset <a class=\"anchor\" id=\"split\"></a>\n",
        "\n",
        "Here we split the dataset into three parts for model training (60% of the sample), validation (20%), and final assessment (the 20% set aside as the test or map reference dataset).\n",
        "\n",
        "The splits are confined to the usable sample, which is defined as samples not falling into class 3 and those with at least 2/3 observers agreeing on the class. This decision is made based on the simplified sample scheme (class2), rather than the full scheme (class). The resulting splits are denoted in a column called `usage` (this is distinct from the column `use`, which was used to filter out unusable observations).\n",
        "\n",
        "Values of \"unusable\" in the `usage` column indicate observations that were not usable because of their low agreement or uncertain class.  They are included here for completeness, and in case they help with evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1aae09-9860-4c2e-82e8-e1d8c8f3d898",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "5e1aae09-9860-4c2e-82e8-e1d8c8f3d898",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) the splitting function\n",
        "train_split = input(\"What proportion of the sample should be assigned\"\\\n",
        "                    \" to training?: \")\n",
        "validation_split = input(\"What proportion of the sample should be assigned\"\\\n",
        "                         \" to validation?: \")\n",
        "test_split = input(\"What proportion of the sample should be assigned\"\\\n",
        "                   \" to test/reference?: \")\n",
        "\n",
        "# Check that the splits sum to 1\n",
        "splits = np.array([train_split, validation_split, test_split]).astype(float)\n",
        "split_string = f\"The splits sum to {splits.sum()}, but must equal 1, \"\\\n",
        "    \"please try again\"\n",
        "assert splits.sum() == 1, split_string\n",
        "\n",
        "#Set random seed for train/validation/reference split\n",
        "seed = 999\n",
        "train, test = train_test_split(combined, test_size=(1-splits[0]),\n",
        "                                train_size=splits[0],\n",
        "                                random_state=seed)\n",
        "\n",
        "val, ref = train_test_split(test, test_size=splits[2],\n",
        "                            train_size=splits[1],\n",
        "                            random_state=seed)\n",
        "out = pd.concat(\n",
        "    [train.assign(usage=\"train\"), val.assign(usage=\"validate\"),\n",
        "    ref.assign(usage=\"map_reference/test\")]\n",
        ").reset_index(drop=True)\n",
        "out_pl = out.drop(columns=['Clust'])\n",
        "\n",
        "out_pl.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514a3272",
      "metadata": {
        "id": "514a3272"
      },
      "source": [
        "### Combine and export to csv <a class=\"anchor\" id=\"combine\"></a>\n",
        "\n",
        "The ineligible portion of the sample is also added back for completeness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb34864d-3d97-4cf4-b00f-2c6b0c0be69c",
      "metadata": {
        "id": "bb34864d-3d97-4cf4-b00f-2c6b0c0be69c",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title (RUN) Export sample\n",
        "\n",
        "gdrive_folder = input(f\"Enter the name of the output folder: \\n\\n\")\n",
        "csv_name = input(f\"Enter the name of the output csv file: \\n\\n\")\n",
        "\n",
        "output_dir = f\"{root}/MyDrive/{gdrive_folder}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "outpath = os.path.join(output_dir, csv_name)\n",
        "\n",
        "with open(outpath, 'w') as f:\n",
        "    out.to_csv(f, float_format='{:f}'.format, encoding='utf-8', index=False)\n",
        "\n",
        "print('file exported')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ab4ddf9",
      "metadata": {
        "id": "7ab4ddf9"
      },
      "source": [
        "And their locations on a map"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title (RUN) Display results\n",
        "\n",
        "# For the usage category\n",
        "color_mapping = {\n",
        "    'train': 'blue',\n",
        "    'validate': 'green',\n",
        "    'map_reference/test': 'red',\n",
        "    'unusable': 'gray'\n",
        "}\n",
        "\n",
        "m = folium.Map(location=[out['Lat'].mean(), out['Lon'].mean()], zoom_start=7)\n",
        "scatter_group_usage = folium.FeatureGroup(name='Usage')\n",
        "\n",
        "scatter_group_mode = folium.FeatureGroup(name='Mode')\n",
        "\n",
        "# Create legend for 'usage'\n",
        "legend_html_usage = '''\n",
        "<div style=\"position: fixed; bottom: 50px; left: 50px; background-color: white; border: 2px solid grey; z-index: 9999; padding: 10px;\">\n",
        "    <h4>Usage</h4>\n",
        "    <i style=\"background: blue; border-radius: 50%; width: 18px; height: 18px; display: inline-block;\"></i> Train<br>\n",
        "    <i style=\"background: green; border-radius: 50%; width: 18px; height: 18px; display: inline-block;\"></i> Validate<br>\n",
        "    <i style=\"background: red; border-radius: 50%; width: 18px; height: 18px; display: inline-block;\"></i> Map Reference/Test<br>\n",
        "    <i style=\"background: gray; border-radius: 50%; width: 18px; height: 18px; display: inline-block;\"></i> Unusable<br>\n",
        "</div>\n",
        "'''\n",
        "legend_usage = folium.Element(legend_html_usage)\n",
        "m.get_root().html.add_child(legend_usage)\n",
        "\n",
        "# Create legend for 'mode'\n",
        "legend_html_mode = '''\n",
        "<div style=\"position: fixed; bottom: 50px; left: 230px; background-color: white; border: 2px solid grey; z-index: 9999; padding: 10px;\">\n",
        "    <h4>Mode</h4>\n",
        "    <i style=\"background: purple; border-radius: 50%; width: 18px; height: 18px; display: inline-block;\"></i> Absence<br>\n",
        "    <i style=\"background: yellow; border-radius: 50%; width: 18px; height: 18px; display: inline-block;\"></i> Presence<br>\n",
        "    <i style=\"background: black; border-radius: 50%; width: 18px; height: 18px; display: inline-block;\"></i> Not Sure<br>\n",
        "</div>\n",
        "'''\n",
        "legend_mode = folium.Element(legend_html_mode)\n",
        "m.get_root().html.add_child(legend_mode)\n",
        "\n",
        "for usage, color in color_mapping.items():\n",
        "    subset = out[out['usage'] == usage]\n",
        "    for _, row in subset.iterrows():\n",
        "        folium.CircleMarker(location=[row['Lat'], row['Lon']], radius=1, color=color, fill=True, fill_color=color, fill_opacity=1).add_to(scatter_group_usage)\n",
        "\n",
        "for mode in range(3):  # 0, 1, 2\n",
        "    subset = out[out['mode'] == mode]\n",
        "    color = ['purple', 'yellow', 'black'][mode]\n",
        "    for _, row in subset.iterrows():\n",
        "        folium.CircleMarker(location=[row['Lat'], row['Lon']], radius=1, color=color, fill=True, fill_color=color, fill_opacity=1).add_to(scatter_group_mode)\n",
        "\n",
        "# Add the feature groups to the map\n",
        "scatter_group_usage.add_to(m)\n",
        "scatter_group_mode.add_to(m)\n",
        "\n",
        "# Add OpenStreetMap layer to the map\n",
        "folium.TileLayer('openstreetmap').add_to(m)\n",
        "\n",
        "# Add a layer control to toggle between 'usage' and 'mode' scatter plots and OpenStreetMap layer\n",
        "folium.LayerControl(collapsed=False).add_to(m)\n",
        "\n",
        "m"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c2XVQKCYTC1O"
      },
      "id": "c2XVQKCYTC1O",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}