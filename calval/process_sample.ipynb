{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "view-in-github",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agroimpacts/VegMapper/blob/dev-calval-simplify/calval/process_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c515862",
      "metadata": {
        "id": "3c515862"
      },
      "source": [
        "# Creating a single training/validation/test set from multiple Collect Earth projects\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c59e929",
      "metadata": {
        "id": "0c59e929"
      },
      "source": [
        "### Table of Contents\n",
        "\n",
        "* [Overview](#overview)\n",
        "* [Set-up](#setup)\n",
        "* [Sample preparation](#sample-prep)\n",
        "    * [Read-in, reshape, and recode](#reshape-recode)\n",
        "    * [Simplify the classes](#simplify)\n",
        "    * [Calculate sample agreement](#agreement)\n",
        "* [Split the dataset](#split)\n",
        "    * [Combine and convert to spatial](#combine)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af718f4a",
      "metadata": {
        "id": "af718f4a"
      },
      "source": [
        "## Overview <a class=\"anchor\" id=\"overview\"></a>\n",
        "This notebook demonstrates how several Collect Earth Online projects can be:\n",
        "\n",
        "1. Provide functionality to check the structure and validity of user input for modeling; Yet, users are responsible for providing data in good format.\n",
        "2. Re-code the class values and rename the column names.\n",
        "2. Merged into a single dataset that provide a single label for each sample point and an estimate of label uncertainty;\n",
        "3. Split into training, validation, and test (or map reference) samples.\n",
        "\n",
        "The example data that can be used for this notebook, if you don't bring your own, are the results of three Collect Earth Online projects that were captured over the Department of Ucayali, Peru. They are in the VegMapper repo under the calval/data folder. Each project csv represents the efforts of an individual (or group of individuals working in the same project) to label 1350 points, classifying each into 1 of 4 classes: not oil palm; young oil palm; mature oil palm;  unsure. The datasets preserve all the information from these projects, although user email addresses were anonymized.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e56ab0",
      "metadata": {
        "id": "34e56ab0"
      },
      "source": [
        "## Sample preparation <a class=\"anchor\" id=\"sample-prep\"></a>\n",
        "Load packages, setup configuations, define a helper function..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0968b28e",
      "metadata": {
        "cellView": "form",
        "id": "0968b28e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#@title (RUN) Setup code\n",
        "import os\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    root = '/content/gdrive'\n",
        "    drive.mount(root)\n",
        "    repo_path = f\"{root}/MyDrive/repos\"\n",
        "    clone_path = 'https://github.com/agroimpacts/VegMapper.git'\n",
        "    if not os.path.exists(repo_path):\n",
        "        print(f\"Making {repo_path}\")\n",
        "        os.makedirs(repo_path, exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(f\"{repo_path}/VegMapper\"):\n",
        "        !git -C \"{repo_path}\" clone \"{clone_path}\"\n",
        "    else:\n",
        "        !git -C \"{repo_path}/VegMapper\" pull\n",
        "\n",
        "    os.chdir(f\"{repo_path}/VegMapper\")\n",
        "\n",
        "except ImportError:\n",
        "    # Start from current directory and move up until 'VegMapper' is found\n",
        "    curr = os.path.abspath(os.getcwd())\n",
        "    while True:\n",
        "        if os.path.basename(curr) == \"VegMapper\":\n",
        "            root = curr\n",
        "            repo_path = root\n",
        "            os.chdir(root)\n",
        "            break\n",
        "        parent = os.path.dirname(curr)\n",
        "        if parent == curr:\n",
        "            raise FileNotFoundError(\"VegMapper directory not found in path.\")\n",
        "        curr = parent\n",
        "\n",
        "# from datetime import datetime as dt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Import sample_utils function\n",
        "from vegmapper.calval.label_utils import *\n",
        "from functools import partial\n",
        "import folium"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "V5ck87okI3TH",
      "metadata": {
        "id": "V5ck87okI3TH"
      },
      "source": [
        "To load the CSV files, you only need to open the directory on the left panel of your Colab notebook. Then, navigate to the directory where you have the files, click on the three dots menue to the right of the file names, and select 'Copy Path.' Finally, paste the path in the box below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0IrPNN97mV-",
      "metadata": {
        "cellView": "form",
        "id": "d0IrPNN97mV-"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) Load CEO Project CSVs\n",
        "fs = project_file_selector()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yDZ1npQs1l2y",
      "metadata": {
        "id": "yDZ1npQs1l2y"
      },
      "source": [
        "**Note**: it is important to make sure that the CEO project files come from the same project, such each plot_id represents the same location. It is theoretically possible that 2 or more projects could have the same numbers of plots and plot_id numbers, but each plot_id represents a different location, in which case the results here will not be valid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jWtgWHDFSToU",
      "metadata": {
        "cellView": "form",
        "id": "jWtgWHDFSToU"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) Check that projects have matching observations/columns\n",
        "match_ceo_projects(fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LcftjOHn-xVm",
      "metadata": {
        "cellView": "form",
        "id": "LcftjOHn-xVm"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) Select the columns containing the class variable\n",
        "new_col_names, rename_dict = select_columns(fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5De1DlmtWGoA",
      "metadata": {
        "cellView": "form",
        "id": "5De1DlmtWGoA"
      },
      "outputs": [],
      "source": [
        "# @title Provide a numerical code presence (e.g. 1), absence (e.g. 0) and unsure (e.g. 2, if present)\n",
        "recode_dict = {}\n",
        "\n",
        "# Iterate through new_col_names and get user input for values\n",
        "for column_name in new_col_names:\n",
        "    arbitrary_number = int(\n",
        "        input(f\"Enter a number for the '{column_name}' category: \")\n",
        "    )\n",
        "    recode_dict[column_name] = arbitrary_number\n",
        "\n",
        "print(\"Updated recode_dict:\")\n",
        "print(recode_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88b2fe77-3b6e-4b03-aa71-67529e0993ab",
      "metadata": {
        "id": "88b2fe77-3b6e-4b03-aa71-67529e0993ab"
      },
      "source": [
        "### Read-in, reshape, and recode classes <a class=\"anchor\" id=\"reshape-recode\"></a>\n",
        "The first step is to combine the three datasets into a single dataset, with the columns from each of the three CEO projects, and to recode the four classes into a single column with values 0 (absence),  1 (presence), and 2 (unsure, if this category exists). After this step, there will be one column per CEO project. Each column contains the recoded classes, and the column is named for the CEO project.\n",
        "When a category value for a CEO project is -99, it means the user didn't choose a category for that specific sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fFPKSi2HA7ti",
      "metadata": {
        "id": "fFPKSi2HA7ti"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) Process and combine csvs\n",
        "label_name = \"labeler\"\n",
        "\n",
        "if len(fs) == 1:\n",
        "    dat = process_csv(fs[0], rename_dict, recode_dict, new_col_names,\n",
        "                      key_col=[\"Point_ID\", \"Clust\", \"email\"])\n",
        "    labelers = list(dat[\"email\"].unique())\n",
        "    dats = [dat.query(\"email==@labeler\").drop(columns=\"email\", axis=0)\n",
        "            for labeler in labelers]\n",
        "else:\n",
        "        # Define a partial function with fixed arguments\n",
        "    process_csv_partial = partial(process_csv, rename_dict=rename_dict,\n",
        "                                  recode_dict=recode_dict,\n",
        "                                  new_col_names=new_col_names)\n",
        "\n",
        "    # Process ceo-survey-users one by one\n",
        "    dats = list(map(process_csv_partial, fs))\n",
        "\n",
        "# Combine three datasets into one\n",
        "num_labelers = len(dats)\n",
        "columns_to_int = [f\"ceo-survey-user{d}\" for d in range(1, num_labelers+1)]\n",
        "combined = combine_labelers(dats, by=[\"Point_ID\", \"Clust\"],\n",
        "                            label_name=label_name)\n",
        "combined_pl = combined.drop(columns=['Clust'])\n",
        "# columns_to_int = ['ceo-survey-user1', 'ceo-survey-user2', 'ceo-survey-user3']\n",
        "combined_pl[columns_to_int] = combined_pl[columns_to_int]\\\n",
        "    .apply(lambda x: x.fillna(-99).astype(int))\n",
        "combined_pl.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94baf77b",
      "metadata": {
        "id": "94baf77b"
      },
      "source": [
        "### Calculate sample agreement <a class=\"anchor\" id=\"agreement\"></a>\n",
        "The next step is to calculate some agreement metrics across the various projects. The primary approach is to calculate the proportion of projects that selected the most common class (e.g. if there were three projects, and in two of the projects the observers labelled a particular sample as belonging to class 1 and the third labelled it as class 0, the sample is classified as 1, the modal class). If there are three projects, values can be either 0.333, 0.667, or 1. If there are four, they can 0.25, 0.5, 0.75, or 1.\n",
        "\n",
        "Although there may be multiple classes representing presence and absence, agreement is calculated only for the simplifed classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a845bbb",
      "metadata": {
        "cellView": "form",
        "id": "5a845bbb",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# @title (RUN) Agreement mode\n",
        "# labels = []\n",
        "\n",
        "# for i in range(1, num_labelers + 1):\n",
        "#     file_name = os.path.splitext(os.path.basename(fs[i-1]))[0]\n",
        "#     labels.append(file_name)\n",
        "combined[['class', 'confidence', 'count']] = combined[columns_to_int]\\\n",
        "    .apply(get_mode_occurence, axis=1, result_type='expand')\n",
        "# combined[['class', 'confidence']] = combined[labels]\\\n",
        "#     .apply(get_mode_occurence, axis=1, result_type='expand')\n",
        "pd.set_option('display.max_rows', None)\n",
        "#print(combined)\n",
        "\n",
        "# # we can set the mode to -9999 if there is no agreement\n",
        "# #(mode_freq = 1/num_labelers)\n",
        "combined.loc[combined['confidence'] <= 1/num_labelers, 'class'] = -9999\n",
        "combined = combined.drop(combined[combined['class'] == -9999].index)\n",
        "combined_shp = list(combined.shape)\n",
        "print(f\"Combined project has {combined_shp[0]} rows, {combined_shp[1]} columns\")\n",
        "\n",
        "# columns_to_int = ['ceo-survey-user1', 'ceo-survey-user2', 'ceo-survey-user3',\\\n",
        "#                   'class']\n",
        "columns_to_int2 = columns_to_int\n",
        "columns_to_int2.append(\"class\")\n",
        "combined[columns_to_int2] = combined[columns_to_int2]\\\n",
        "    .apply(lambda x: x.fillna(-99).astype(int))\n",
        "combined_pl2 = combined.drop(columns=['Clust'])\n",
        "combined_pl2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6ab33e9",
      "metadata": {
        "id": "c6ab33e9"
      },
      "source": [
        "We can then calculate the average agreement per sample to get a sense of the uncertainty in labels for each class, for all 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3cbab14",
      "metadata": {
        "cellView": "form",
        "id": "d3cbab14"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) Calculate average agreement per sample\n",
        "agreement = combined.groupby(\"class\").mean()\n",
        "agreement = agreement.rename(columns={\"confidence\": \"mean confidence\"})\n",
        "print(agreement[['mean confidence']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b5b0926",
      "metadata": {
        "id": "5b5b0926"
      },
      "source": [
        "## Split the dataset <a class=\"anchor\" id=\"split\"></a>\n",
        "\n",
        "Here we split the dataset into three parts for model training, validation, and final assessment (the portion set aside as the test or map reference dataset), according to the proportions you specify.\n",
        "\n",
        "The splits are confined to the usable sample, which is defined as samples not falling into the unsure class and those where there was modal agreement on the class. The resulting splits are denoted in a column called `usage`.\n",
        "\n",
        "Values of \"unusable\" in the `usage` column indicate observations that were not usable because of their low agreement or classified as unsure.  They are included here for completeness, and in case they help with evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xgnAiFs8cEk-",
      "metadata": {
        "cellView": "form",
        "id": "xgnAiFs8cEk-"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) the splitting function\n",
        "while True:\n",
        "    train_split = float(\n",
        "        input(\"What proportion of the sample should be assigned to training?: \")\n",
        "    )\n",
        "    validation_split = float(\n",
        "        input(\"What proportion should be assigned to validation?: \")\n",
        "    )\n",
        "    test_split = float(\n",
        "        input(\"What proportion of the sample should be assigned to \"\\\n",
        "              \"test/reference?: \")\n",
        "    )\n",
        "\n",
        "    # Ensure that the splits sum to 1 or are less than 1\n",
        "    split_sum = train_split + validation_split + test_split\n",
        "\n",
        "    if abs(split_sum - 1) < 1e-9:\n",
        "        break\n",
        "    else:\n",
        "        print(f\"The splits sum to {split_sum}, but must equal 1. \\n\"\\\n",
        "              \"Please try again.\")\n",
        "\n",
        "seed = 999\n",
        "\n",
        "n_samples = len(combined)\n",
        "n_train = int(n_samples * train_split)\n",
        "n_val = int(n_samples * validation_split)\n",
        "n_test = n_samples - n_train - n_val\n",
        "\n",
        "train = combined.sample(n_train, random_state=seed)\n",
        "remaining = combined.drop(train.index)\n",
        "val = remaining.sample(n_val, random_state=seed)\n",
        "ref = remaining.drop(val.index)\n",
        "\n",
        "out = pd.concat(\n",
        "    [train.assign(usage=\"train\"), val.assign(usage=\"validate\"),\n",
        "     ref.assign(usage=\"map_reference/test\")]\n",
        ").reset_index(drop=True)\n",
        "out_pl = out.drop(columns=['Clust'])\n",
        "\n",
        "out_pl.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514a3272",
      "metadata": {
        "id": "514a3272"
      },
      "source": [
        "### Combine and export to csv <a class=\"anchor\" id=\"combine\"></a>\n",
        "\n",
        "The ineligible portion of the sample is also added back for completeness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb34864d-3d97-4cf4-b00f-2c6b0c0be69c",
      "metadata": {
        "cellView": "form",
        "id": "bb34864d-3d97-4cf4-b00f-2c6b0c0be69c"
      },
      "outputs": [],
      "source": [
        "#@title (RUN) Export sample\n",
        "gdrive_folder = input(f\"Enter the name of the output folder: \\n\\n\")\n",
        "csv_name = input(f\"Enter the name of the output csv file: \\n\\n\")\n",
        "\n",
        "if \"gdrive\" in root:\n",
        "    output_dir = f\"{root}/MyDrive/{gdrive_folder}\"\n",
        "else:\n",
        "    output_dir = f\"{root}/{gdrive_folder}\"\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "outpath = os.path.join(output_dir, csv_name)\n",
        "\n",
        "with open(outpath, 'w') as f:\n",
        "    out.to_csv(f, float_format='{:f}'.format, encoding='utf-8', index=False)\n",
        "\n",
        "print('file exported')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ab4ddf9",
      "metadata": {
        "id": "7ab4ddf9"
      },
      "source": [
        "And their locations on a map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2XVQKCYTC1O",
      "metadata": {
        "cellView": "form",
        "id": "c2XVQKCYTC1O"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) Display results\n",
        "\n",
        "# For the usage category\n",
        "color_mapping = {\n",
        "    'train': 'blue',\n",
        "    'validate': 'green',\n",
        "    'map_reference/test': 'red',\n",
        "    'unusable': 'gray'\n",
        "}\n",
        "\n",
        "m = folium.Map(location=[out['Lat'].mean(), out['Lon'].mean()], zoom_start=7)\n",
        "scatter_group_usage = folium.FeatureGroup(name='Usage')\n",
        "\n",
        "scatter_group_class = folium.FeatureGroup(name='Class')\n",
        "\n",
        "# Create legend for 'usage'\n",
        "legend_html_usage = '''\n",
        "<div style=\"position: fixed; bottom: 50px; left: 50px; background-color: white;\\\n",
        "border: 2px solid grey; z-index: 9999; padding: 10px;\">\n",
        "    <h4>Usage</h4>\n",
        "    <i style=\"background: blue; border-radius: 50%; width: 18px; height: 18px;\\\n",
        "    display: inline-block;\"></i> Train<br>\n",
        "    <i style=\"background: green; border-radius: 50%; width: 18px; height: 18px;\\\n",
        "    display: inline-block;\"></i> Validate<br>\n",
        "    <i style=\"background: red; border-radius: 50%; width: 18px; height: 18px;\\\n",
        "    display: inline-block;\"></i> Map Reference/Test<br>\n",
        "    <i style=\"background: gray; border-radius: 50%; width: 18px; height: 18px;\\\n",
        "    display: inline-block;\"></i> Unusable<br>\n",
        "</div>\n",
        "'''\n",
        "legend_usage = folium.Element(legend_html_usage)\n",
        "m.get_root().html.add_child(legend_usage)\n",
        "\n",
        "# Create legend for 'class'\n",
        "legend_html_class = '''\n",
        "<div style=\"position: fixed; bottom: 50px; left: 230px; background-color: white;\\\n",
        "border: 2px solid grey; z-index: 9999; padding: 10px;\">\n",
        "    <h4>Class</h4>\n",
        "    <i style=\"background: purple; border-radius: 50%; width: 18px; height: 18px;\\\n",
        "    display: inline-block;\"></i> Absence<br>\n",
        "    <i style=\"background: yellow; border-radius: 50%; width: 18px; height: 18px;\\\n",
        "    display: inline-block;\"></i> Presence<br>\n",
        "    <i style=\"background: black; border-radius: 50%; width: 18px; height: 18px;\\\n",
        "    display: inline-block;\"></i> Not Sure<br>\n",
        "</div>\n",
        "'''\n",
        "legend_class = folium.Element(legend_html_class)\n",
        "m.get_root().html.add_child(legend_class)\n",
        "\n",
        "for usage, color in color_mapping.items():\n",
        "    subset = out[out['usage'] == usage]\n",
        "    for _, row in subset.iterrows():\n",
        "        folium.CircleMarker(location=[row['Lat'], row['Lon']], radius=1, \\\n",
        "                            color=color, fill=True, fill_color=color,\\\n",
        "                            fill_opacity=1).add_to(scatter_group_usage)\n",
        "\n",
        "for class_name in range(3):  # 0, 1, 2\n",
        "    subset = out[out['class'] == class_name]\n",
        "    color = ['purple', 'yellow', 'black'][class_name]\n",
        "    for _, row in subset.iterrows():\n",
        "        folium.CircleMarker(location=[row['Lat'], row['Lon']], radius=1,\\\n",
        "                            color=color, fill=True, fill_color=color,\\\n",
        "                            fill_opacity=1).add_to(scatter_group_class)\n",
        "\n",
        "# Add the feature groups to the map\n",
        "scatter_group_usage.add_to(m)\n",
        "scatter_group_class.add_to(m)\n",
        "\n",
        "# Add OpenStreetMap layer to the map\n",
        "folium.TileLayer('openstreetmap').add_to(m)\n",
        "\n",
        "# Add a layer control to toggle between 'usage' and 'class' scatter plots and\n",
        "#OpenStreetMap layer\n",
        "folium.LayerControl(collapsed=False).add_to(m)\n",
        "\n",
        "m"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "vegmapper",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}