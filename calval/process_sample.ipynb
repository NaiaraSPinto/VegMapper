{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agroimpacts/VegMapper/blob/dev-calval-simplify/calval/process_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c515862",
      "metadata": {
        "id": "3c515862"
      },
      "source": [
        "# Creating a single training/validation/test set from multiple Collect Earth projects\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c59e929",
      "metadata": {
        "id": "0c59e929"
      },
      "source": [
        "### Table of Contents\n",
        "\n",
        "* [Overview](#overview)\n",
        "* [Set-up](#setup)\n",
        "* [Sample preparation](#sample-prep)\n",
        "    * [Read-in, reshape, and recode](#reshape-recode)\n",
        "    * [Simplify the classes](#simplify)\n",
        "    * [Calculate sample agreement](#agreement)\n",
        "* [Split the dataset](#split)\n",
        "    * [Combine and convert to spatial](#combine)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af718f4a",
      "metadata": {
        "id": "af718f4a"
      },
      "source": [
        "## Overview <a class=\"anchor\" id=\"overview\"></a>\n",
        "This notebook demonstrates how several Collect Earth Online projects can be:\n",
        "\n",
        "1. Provide functionality to check the structure and validity of user input for modeling; Yet, users are responsible for providing data in good format.\n",
        "2. Re-code the class values and rename the column names.\n",
        "2. Merged into a single dataset that provide a single label for each sample point and an estimate of label uncertainty;\n",
        "3. Split into training, validation, and test (or map reference) samples.\n",
        "\n",
        "The data used in this demonstration are the results of three Collect Earth Online projects that were captured over the Department of Ucayali, Peru. Each project represents the efforts of an individual (or group of individuals working in the same project) to label 1350 points, classifying each into 1 of 4 classes: not oil palm; young oil palm; mature oil palm;  unsure. The datasets preserve all the information from these projects, although user email addresses were anonymized."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e56ab0",
      "metadata": {
        "id": "34e56ab0"
      },
      "source": [
        "## Sample preparation <a class=\"anchor\" id=\"sample-prep\"></a>\n",
        "Load packages, setup configuations, define a helper function..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0968b28e",
      "metadata": {
        "id": "0968b28e",
        "tags": [],
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# from label_utils import load_csv, subset_cols, rename_cols,\\\n",
        "#     check_exclusive, recode, combine_labelers, get_mode_and_occurence\n",
        "\n",
        "#@title (RUN) Setup code\n",
        "## Mount Drive\n",
        "from google.colab import drive\n",
        "root = '/content/gdrive'\n",
        "drive.mount(root)\n",
        "\n",
        "## Clone and/or update VegMapper\n",
        "import os\n",
        "# from datetime import datetime as dt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "repo_path = f\"{root}/MyDrive/repos\"\n",
        "clone_path = 'https://github.com/agroimpacts/VegMapper.git'\n",
        "if not os.path.exists(repo_path):\n",
        "    print(f\"Making {repo_path}\")\n",
        "    os.makedirs(repo_path, exist_ok=True)\n",
        "\n",
        "if not os.path.exists(f\"{repo_path}/VegMapper\"):\n",
        "    !git -C \"{repo_path}\" clone \"{clone_path}\"\n",
        "else:\n",
        "    !git -C \"{repo_path}/VegMapper\" pull\n",
        "\n",
        "os.chdir(f\"{repo_path}/VegMapper\")\n",
        "\n",
        "# Import sample_utils function\n",
        "from vegmapper.calval.label_utils import *\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Loading CSVs\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        num_users = int(input(\"Enter the number of CEO projects (The number of CEO projects must be more than 2): \"))\n",
        "        if num_users < 2:\n",
        "            print(\"The number of CEO projects must be at least 2.\")\n",
        "        else:\n",
        "            break\n",
        "    except ValueError:\n",
        "        print(\"Invalid input. Please enter a valid number.\")\n",
        "\n",
        "# Initialize the list to store file paths\n",
        "fs = []\n",
        "\n",
        "# Loop to input file paths for each user\n",
        "for i in range(num_users):\n",
        "    while True:\n",
        "        file_path = os.path.join(\"./calval/data/\", input(f\"Enter the CSV file name for user {i+1}: \"))\n",
        "        if not file_path:\n",
        "            print(\"File name cannot be empty.\")\n",
        "        else:\n",
        "            fs.append(file_path)\n",
        "            break"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d0IrPNN97mV-"
      },
      "id": "d0IrPNN97mV-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Defining columns\n",
        "# Initialize the new_col_name variable as an empty list\n",
        "new_col_names = []\n",
        "\n",
        "# Hardcoded column renames\n",
        "rename_dict = {\n",
        "    \"plot_id\": \"Point_ID\",\n",
        "    \"pl_cluster\": \"Clust\",\n",
        "    \"center_lat\": \"Lat\",\n",
        "    \"center_lon\": \"Lon\"\n",
        "}\n",
        "\n",
        "# Get user input for additional column renames\n",
        "num_additional_columns = int(\n",
        "    input(\"Enter the number of additional columns to rename: \")\n",
        ")\n",
        "for i in range(num_additional_columns):\n",
        "    old_column = input(\n",
        "        f\"Enter the **CURRENT** column name for additional column {i+1}: \"\n",
        "    )\n",
        "    new_column = input(\n",
        "        f\"Enter the **NEW** column name for additional column {i+1}: \"\n",
        "    )\n",
        "    rename_dict[old_column] = new_column\n",
        "    new_col_names.append(new_column)\n",
        "\n",
        "print(\"Updated rename_dict:\")\n",
        "print(rename_dict)\n",
        "print(\"new_col_name:\")\n",
        "print(new_col_names)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pua0hgl6Z1tf"
      },
      "id": "pua0hgl6Z1tf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Defining which columns represents presence (1), absence (0) or unsure (2)\n",
        "\n",
        "recode_dict = {}\n",
        "\n",
        "# Iterate through new_col_names and get user input for values\n",
        "for column_name in new_col_names:\n",
        "    arbitrary_number = int(input(f\"Enter a number for the '{column_name}' category: \"))\n",
        "    recode_dict[column_name] = arbitrary_number\n",
        "\n",
        "print(\"Updated recode_dict:\")\n",
        "print(recode_dict)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5De1DlmtWGoA"
      },
      "id": "5De1DlmtWGoA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "88b2fe77-3b6e-4b03-aa71-67529e0993ab",
      "metadata": {
        "id": "88b2fe77-3b6e-4b03-aa71-67529e0993ab"
      },
      "source": [
        "### Read-in, reshape, and recode classes <a class=\"anchor\" id=\"reshape-recode\"></a>\n",
        "The first step was to combine the three datasets into a single dataset, with the columns from each of the three CEO projects, and to recode the four classes into a single column with values 0 (absence),  1 (presence), and 2 (unsure). At this step, we end up with 3 columns, 1 per completed CEO project: `cl1` = samples from project 1, `cl2` = samples from project 2, `cl3` = samples from project 3. Each column contains the recoded classes (note the renaming of the columns is done in the next code chunk)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dbbf0f2",
      "metadata": {
        "id": "8dbbf0f2"
      },
      "source": [
        "### Simplify the classes <a class=\"anchor\" id=\"simplify\"></a>\n",
        "\n",
        "In this step, a single classification is created by finding the modal class for each sample point across the 3 groups' results. This creates a new `class` column, which provides the class from the majority opinion.\n",
        "\n",
        "We repeat this same step again after first collapsing, within each of the `cl1:cl3` columns, the two oil palm classes into a single *oil palm* class with value = 1--*not oil palm* remains 0, and *unsure* remains 3. The modal function was re-run to create a new consensus class, called `class2`. We recommend that `class2` be used for modelling, while `class` may be useful for understanding error patterns."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Process and combine csvs\n",
        "\n",
        "label_name = \"labeler\"\n",
        "# Define a partial function with fixed arguments\n",
        "process_csv_partial = partial(process_csv, rename_dict=rename_dict,\n",
        "                              recode_dict=recode_dict, new_col_names=new_col_names)\n",
        "\n",
        "# Process ceo-survey-users one by one\n",
        "dats = list(map(process_csv_partial, fs))\n",
        "\n",
        "# Combine three datasets into one\n",
        "combined = combine_labelers(dats, by=[\"Point_ID\", \"Clust\"], label_name=label_name)\n",
        "combined.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fFPKSi2HA7ti"
      },
      "id": "fFPKSi2HA7ti",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "94baf77b",
      "metadata": {
        "id": "94baf77b"
      },
      "source": [
        "### Calculate sample agreement <a class=\"anchor\" id=\"agreement\"></a>\n",
        "The next step was to calculate some agreement metrics across the three groups' samples. The primary approach was to calculate the proportion of labelling teams that selected the modal class. Since there were just three teams in this example, values were either 0.333, 0.667, 1. This agreement was calculated across for both the original classification scheme (class: 0-3) and the simplifed scheme (), with columns `agree` and `agree2` providing the respective proportions for each observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a845bbb",
      "metadata": {
        "id": "5a845bbb",
        "tags": [],
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Agreement mode\n",
        "\n",
        "num_labelers = len(fs)\n",
        "\n",
        "labels = []\n",
        "\n",
        "for i in range(1, num_labelers + 1):\n",
        "    label = f\"labeler_{i}\"\n",
        "    labels.append(label)\n",
        "\n",
        "combined[['mode', 'mode_agreement']] = combined[labels].apply(get_mode_and_occurence, axis=1, result_type='expand')\n",
        "pd.set_option('display.max_rows', None)\n",
        "#print(combined)\n",
        "\n",
        "# we can set the mode to -9999 if there is no agreement (mode_freq = 1/num_labelers)\n",
        "combined.loc[combined['mode_agreement'] <= 1/3, 'mode'] = -9999\n",
        "\n",
        "combined = combined.drop(combined[combined['mode'] == -9999].index)\n",
        "print(combined.shape)\n",
        "\n",
        "combined.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6ab33e9",
      "metadata": {
        "id": "c6ab33e9"
      },
      "source": [
        "We can then calculate the average agreement per sample to get a sense of the uncertainty in labels for each class, for all 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3cbab14",
      "metadata": {
        "id": "d3cbab14",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Average agreement per sample\n",
        "agreement = combined.groupby(\"mode\").mean()\n",
        "agreement = agreement.rename(columns={\"mode_agreement\": \"mean agreement\"})\n",
        "print(agreement[['mean agreement']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1ba24d-3edd-42ee-abef-01b3c7ef919c",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "de1ba24d-3edd-42ee-abef-01b3c7ef919c",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Check the result\n",
        "combined.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b2e124a",
      "metadata": {
        "id": "4b2e124a"
      },
      "source": [
        "And for the reduced set of classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b5b0926",
      "metadata": {
        "id": "5b5b0926"
      },
      "source": [
        "## Split the dataset <a class=\"anchor\" id=\"split\"></a>\n",
        "\n",
        "Here we split the dataset into three parts for model training (60% of the sample), validation (20%), and final assessment (the 20% set aside as the test or map reference dataset).\n",
        "\n",
        "The splits are confined to the usable sample, which is defined as samples not falling into class 3 and those with at least 2/3 observers agreeing on the class. This decision is made based on the simplified sample scheme (class2), rather than the full scheme (class). The resulting splits are denoted in a column called `usage` (this is distinct from the column `use`, which was used to filter out unusable observations).\n",
        "\n",
        "Values of \"unusable\" in the `usage` column indicate observations that were not usable because of their low agreement or uncertain class.  They are included here for completeness, and in case they help with evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1aae09-9860-4c2e-82e8-e1d8c8f3d898",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "5e1aae09-9860-4c2e-82e8-e1d8c8f3d898",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Run the split\n",
        "\n",
        "#Set random seed for train/validation/reference split\n",
        "seed = 999\n",
        "train, test = train_test_split(combined, test_size=0.4, train_size=0.6,\n",
        "                               random_state=seed)\n",
        "\n",
        "val, ref = train_test_split(test, test_size=0.5, train_size=0.5,\n",
        "                            random_state=seed)\n",
        "\n",
        "out = pd.concat(\n",
        "    [train.assign(usage=\"train\"), val.assign(usage=\"validate\"),\n",
        "     ref.assign(usage=\"map_reference/test\")]\n",
        ").reset_index(drop=True)\n",
        "out.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514a3272",
      "metadata": {
        "id": "514a3272"
      },
      "source": [
        "### Combine and export to csv <a class=\"anchor\" id=\"combine\"></a>\n",
        "\n",
        "The ineligible portion of the sample is also added back for completeness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb34864d-3d97-4cf4-b00f-2c6b0c0be69c",
      "metadata": {
        "id": "bb34864d-3d97-4cf4-b00f-2c6b0c0be69c",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title (RUN) Export sample\n",
        "gdrive_folder = input(f\"Enter the name of the output folder: \\n\\n\")\n",
        "csv_name = input(f\"Enter the name of the output csv file: \\n\\n\")\n",
        "\n",
        "outpath = f\"{root}/MyDrive/{gdrive_folder}/{csv_name}\"\n",
        "with open(outpath, 'w') as f:\n",
        "    out.to_csv(f, float_format='{:f}'.format, encoding='utf-8',\n",
        "                    index=False)\n",
        "\n",
        "print('file exported')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ab4ddf9",
      "metadata": {
        "id": "7ab4ddf9"
      },
      "source": [
        "And their locations on a map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b00737ac",
      "metadata": {
        "id": "b00737ac",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Plot samples\n",
        "plot_sample = out.copy()\n",
        "\n",
        "usage_dict = {'train': 1, 'validate': 2, \"map_reference/test\": 3, \"unusable\": 4}\n",
        "plot_sample = plot_sample.replace({'usage': usage_dict})\n",
        "\n",
        "print(plot_sample['usage'].unique())\n",
        "\n",
        "rcParams['figure.figsize'] = 10, 10\n",
        "plot_sample.plot.scatter(x='Lon', y='Lat', c='usage', s=12, cmap='viridis')\n",
        "None"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}