{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aaa31c5",
   "metadata": {},
   "source": [
    "## Build Tile Stacks\n",
    "This notebook will read tiles from an s3 bucket and create multi band stacks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22dbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import getpass\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import rasterio.shutil\n",
    "from rasterio.session import AWSSession\n",
    "from rasterio.vrt import WarpedVRT\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import subprocess\n",
    "import boto3\n",
    "\n",
    "from vegmapper import build_stack, build_condensed_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd181b3",
   "metadata": {},
   "source": [
    "## User inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726fb0ea",
   "metadata": {},
   "source": [
    "### Provide here access credentials for AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_s3_key_id = getpass.getpass(\"Enter the S3 user key ID: \")\n",
    "user_access_key = getpass.getpass(\"Enter the S3 user access key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa7001",
   "metadata": {},
   "source": [
    "### Define paths and observation information\n",
    "These fields should match the bucket structure containing the source tiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89127b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'ucayali'\n",
    "observation_date = '2024'\n",
    "bucket_name = \"name_of_your_bucket\"  # Replace with your actual bucket name\n",
    "bucket_base_path = f\"servir_peru/{location}/{observation_date}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83868a81",
   "metadata": {},
   "source": [
    "### Define bands\n",
    "Add/remove here as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_definitions = [\n",
    "    {\"name\": \"VV\", \"subdir\": \"s1/vv\"},\n",
    "    {\"name\": \"VH\", \"subdir\": \"s1/vh\"},\n",
    "    {\"name\": \"RVI\", \"subdir\": \"s1/rvi\"},\n",
    "    {\"name\": \"NDVI\", \"subdir\": \"landsat/ndvi\"},\n",
    "    # {\"name\": \"NDFI\", \"subdir\": \"landsat/ndfi\"},  # Example of an easy addition\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c8058",
   "metadata": {},
   "source": [
    "## S3 bucket session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edcef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_session = boto3.Session(\n",
    "    aws_access_key_id=user_s3_key_id,\n",
    "    aws_secret_access_key=user_access_key,\n",
    "    # region_name=\"your-region\"  # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba617ca9",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032eb609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to list .tif files in a given S3 prefix\n",
    "def list_s3_file_paths(bucket, prefix):\n",
    "    client = boto3_session.client(\"s3\")\n",
    "    paginator = client.get_paginator(\"list_objects_v2\")\n",
    "    paths = []\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            key = obj[\"Key\"]\n",
    "            if key.lower().endswith((\".tif\", \".tiff\")):\n",
    "                paths.append(f\"s3://{bucket}/{key}\")\n",
    "    return paths\n",
    "\n",
    "# Function to extract tile_id like \"h0_v1\"\n",
    "def extract_tile_id(path):\n",
    "    match = re.search(r'h\\d+_v\\d+', path)\n",
    "    return match.group() if match else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3740e93",
   "metadata": {},
   "source": [
    "## Read Tile ID's and setup bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f4ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fetching all file paths for all bands...\")\n",
    "all_band_files = {}  # {band_name: [file paths]}\n",
    "all_paths_flat = []\n",
    "\n",
    "for band in band_definitions:\n",
    "    full_prefix = f\"{bucket_base_path}/{band['subdir']}/\"\n",
    "    print(f\"Looking for {band['name']} files in: s3://{bucket_name}/{full_prefix}\")\n",
    "    files = list_s3_file_paths(bucket_name, full_prefix)\n",
    "    print(f\"Found {len(files)} {band['name']} files\")\n",
    "    all_band_files[band[\"name\"]] = files\n",
    "    all_paths_flat.extend(files)\n",
    "\n",
    "# Get unique tile IDs\n",
    "tile_ids = sorted(set(filter(None, [extract_tile_id(p) for p in all_paths_flat])))\n",
    "print(f\"Found {len(tile_ids)} unique tile(s): {tile_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a8a39",
   "metadata": {},
   "source": [
    "## Prepare Tiles\n",
    "This step will create the multi-band stacks and uploas them to the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb0745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store S3 paths of all generated COG files\n",
    "all_cog_s3_paths = []\n",
    "\n",
    "for tile_id in tile_ids:\n",
    "    print(f\"\\n Processing tile: {tile_id}\")\n",
    "\n",
    "    stack_name = f\"stack_{location}_{observation_date}_{tile_id}\"\n",
    "    stack_s3_path = f\"{bucket_base_path}/multi_sensor_stacks/{stack_name}_cog.tif\"\n",
    "    local_stack = f\"./{location}/opera_rtc/tile_vrts/{stack_name}.tif\"\n",
    "    local_cog = f\"./{location}/opera_rtc/tile_vrts/{stack_name}_cog.tif\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(local_stack), exist_ok=True)\n",
    "\n",
    "    # Gather tile-specific paths for all bands\n",
    "    band_paths = []\n",
    "    band_names = []\n",
    "\n",
    "    for band in band_definitions:\n",
    "        tile_id_nounder = tile_id.replace(\"_\", \"\")  # e.g., h3v2\n",
    "        matching_files = [\n",
    "            p for p in all_band_files[band[\"name\"]]\n",
    "            if tile_id in p or tile_id_nounder in p\n",
    "        ]\n",
    "        if matching_files:\n",
    "            band_paths.extend(matching_files)\n",
    "            band_names.extend([band[\"name\"]] * len(matching_files))\n",
    "        else:\n",
    "            print(f\"!! Missing {band['name']} for tile {tile_id}\")\n",
    "\n",
    "    if not band_paths:\n",
    "        print(f\"!! No valid files found for tile {tile_id}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Convert to GDAL VSI paths\n",
    "    s3_paths = [p.replace(\"s3://\", \"/vsis3/\") for p in band_paths]\n",
    "    aws_session = AWSSession(boto3_session)\n",
    "\n",
    "## Process tiles\n",
    "    # Stack bands\n",
    "    with rasterio.Env(aws_session):\n",
    "        try:\n",
    "            sources = [rasterio.open(p) for p in s3_paths]\n",
    "            meta = sources[0].meta.copy()\n",
    "            meta.update({\n",
    "                \"count\": len(sources),\n",
    "                \"dtype\": sources[0].dtypes[0],\n",
    "                \"driver\": \"GTiff\"\n",
    "            })\n",
    "        \n",
    "            with rasterio.open(local_stack, \"w\", **meta) as dst:\n",
    "                for i, src in enumerate(sources, start=1):\n",
    "                    dst.write(src.read(1), i)\n",
    "                    dst.set_band_description(i, band_names[i - 1])\n",
    "            \n",
    "            for src in sources:\n",
    "                src.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing tile {tile_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "## Convert to COG \n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"gdal_translate\", local_stack, local_cog,\n",
    "            \"-of\", \"COG\",\n",
    "            \"-co\", \"COMPRESS=LZW\",\n",
    "            \"-co\", \"NUM_THREADS=ALL_CPUS\"\n",
    "        ], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error converting to COG for tile {tile_id}: {e}\")\n",
    "        os.remove(local_stack) # Clean up local stack even if COG conversion fails\n",
    "        continue # Skip to next tile if COG conversion fails\n",
    "\n",
    "    # Upload to S3 \n",
    "    try:\n",
    "        boto3_session.client(\"s3\").upload_file(local_cog, bucket_name, stack_s3_path)\n",
    "        print(f\"--> Uploaded: s3://{bucket_name}/{stack_s3_path}\")\n",
    "        all_cog_s3_paths.append(f\"/vsis3/{bucket_name}/{stack_s3_path}\") # Add VSI S3 path for VRT\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading COG for tile {tile_id} to S3: {e}\")\n",
    "\n",
    "    os.remove(local_stack)\n",
    "    print(f\"-> Removed: {local_stack}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6451ea9",
   "metadata": {},
   "source": [
    "## Read and display sample Stack\n",
    "Grab one of the generated stacks and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f44dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open VRT from S3\n",
    "s3_vrt_path = f\"/vsis3/{bucket_name}/{bucket_base_path}/multi_sensor_stacks/stack_ucayali_2024_h1_v1_cog.tif\"\n",
    "\n",
    "# Open the stacked VRT from S3\n",
    "with rasterio.Env(aws_session):\n",
    "    with rasterio.open(s3_vrt_path) as dataset:\n",
    "        band1 = dataset.read(1)  # Read VV\n",
    "        band2 = dataset.read(2)  # Read VH\n",
    "        band3 = dataset.read(3)  # Read RVI\n",
    "        band4 = dataset.read(4)  # Read NDVI\n",
    "        band_names = dataset.descriptions\n",
    "\n",
    "# Display Bands\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "bands = [band1, band2, band3, band4]\n",
    "cmaps = [\"gray\", \"gray\", \"gray\", \"viridis\"]\n",
    "vmin_values = [0, 0, 0, 0.6]\n",
    "vmax_values = [0.4, 0.1, 1.0, 0.9]\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].imshow(bands[i], cmap=cmaps[i], vmin=vmin_values[i], vmax=vmax_values[i])\n",
    "    title = band_names[i] if band_names[i] else f\"Band {i+1}\"\n",
    "    ax[i].set_title(title)\n",
    "    ax[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d42bc",
   "metadata": {},
   "source": [
    "## Create VRT mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f200d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_band_descriptions_to_vrt(vrt_path, reference_tif_path):\n",
    "    \"\"\"Inject band descriptions from a sample COG into the VRT XML.\"\"\"\n",
    "    ref_ds = gdal.Open(reference_tif_path)\n",
    "    descriptions = [ref_ds.GetRasterBand(i + 1).GetDescription() for i in range(ref_ds.RasterCount)]\n",
    "\n",
    "    tree = ET.parse(vrt_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for i, band_elem in enumerate(root.findall(\"VRTRasterBand\")):\n",
    "        if i < len(descriptions) and descriptions[i]:\n",
    "            desc_elem = ET.SubElement(band_elem, \"Description\")\n",
    "            desc_elem.text = descriptions[i]\n",
    "\n",
    "    tree.write(vrt_path)\n",
    "    print(f\"→ Injected band descriptions from {reference_tif_path} into {vrt_path}\")\n",
    "\n",
    "# VRT mosaic creation\n",
    "if all_cog_s3_paths:\n",
    "    print(\"\\n--> Creating VRT mosaic\")\n",
    "    mosaic_name = f\"multiband_tile_mosaic_{location}_{observation_date}.vrt\"\n",
    "    local_mosaic_path = f\"./{location}/opera_rtc/tile_vrts/{mosaic_name}\"\n",
    "    mosaic_s3_path = f\"{bucket_base_path}/multi_sensor_stacks/{mosaic_name}\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(local_mosaic_path), exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Build VRT from COG tiles\n",
    "        gdalbuildvrt_command = [\"gdalbuildvrt\", local_mosaic_path] + all_cog_s3_paths\n",
    "        subprocess.run(gdalbuildvrt_command, check=True)\n",
    "        print(f\"--> Created local VRT mosaic: {local_mosaic_path}\")\n",
    "\n",
    "        # Inject band descriptions from the first tile\n",
    "        reference_tile = all_cog_s3_paths[0]\n",
    "        copy_band_descriptions_to_vrt(local_mosaic_path, reference_tile)\n",
    "\n",
    "        # Upload the VRT to S3\n",
    "        boto3_session.client(\"s3\").upload_file(local_mosaic_path, bucket_name, mosaic_s3_path)\n",
    "        print(f\"--> Uploaded VRT mosaic to S3: s3://{bucket_name}/{mosaic_s3_path}\")\n",
    "\n",
    "        # Cleanup\n",
    "        os.remove(local_mosaic_path)\n",
    "        print(f\"-> Removed local VRT mosaic: {local_mosaic_path}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error creating or uploading VRT mosaic: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during VRT mosaic creation/upload: {e}\")\n",
    "else:\n",
    "    print(\"\\nNo COG files were successfully processed and uploaded to create a VRT mosaic.\")\n",
    "\n",
    "print(\"\\n--> Mosaic Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b835f",
   "metadata": {},
   "source": [
    "## Copy Stacks into a public bucket of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the stacks to another bucket of choice \n",
    "source_bucket = bucket_name\n",
    "source_prefix = \"servir_peru/ucayali/2024/multi_sensor_stacks/\"\n",
    "\n",
    "dest_bucket = \"public\"\n",
    "dest_prefix = \"servir_peru/2024/multi_sensor_stacks/\"\n",
    "\n",
    "# --- Credentials to destination bucket --- # \n",
    "dest_key = getpass.getpass(\"Enter the destination S3 user key ID: \")\n",
    "dest_secret = getpass.getpass(\"Enter the destination S3 user access key: \")\n",
    "# \n",
    "\n",
    "# Create separate sessions for dest bucket\n",
    "dest_session = boto3.Session(\n",
    "    aws_access_key_id=dest_key,\n",
    "    aws_secret_access_key=dest_secret,\n",
    ")\n",
    "\n",
    "# Boto3 clients/resources\n",
    "source_s3 = boto3_session.resource(\"s3\")\n",
    "dest_s3_client = dest_session.client(\"s3\")\n",
    "\n",
    "# List and copy .tif files\n",
    "for obj in source_s3.Bucket(source_bucket).objects.filter(Prefix=source_prefix):\n",
    "    if obj.key.endswith(\".tif\"):\n",
    "        dest_key = obj.key.replace(source_prefix, dest_prefix, 1)\n",
    "        print(f\"Copying → {dest_key}\")\n",
    "        dest_s3_client.copy(\n",
    "            {'Bucket': source_bucket, 'Key': obj.key},\n",
    "            dest_bucket,\n",
    "            dest_key,\n",
    "            ExtraArgs={'ACL': 'public-read'}  # Optional: set to public\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vegmapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
