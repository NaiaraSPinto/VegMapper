{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agroimpacts/VegMapper/blob/dev-calval-simplify/process_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c515862",
      "metadata": {
        "id": "3c515862"
      },
      "source": [
        "# Creating a single training/validation/test set from multiple Collect Earth projects\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c59e929",
      "metadata": {
        "id": "0c59e929"
      },
      "source": [
        "### Table of Contents\n",
        "\n",
        "* [Overview](#overview)\n",
        "* [Set-up](#setup)\n",
        "* [Sample preparation](#sample-prep)\n",
        "    * [Read-in, reshape, and recode](#reshape-recode)\n",
        "    * [Simplify the classes](#simplify)\n",
        "    * [Calculate sample agreement](#agreement)\n",
        "* [Split the dataset](#split)\n",
        "    * [Combine and convert to spatial](#combine)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af718f4a",
      "metadata": {
        "id": "af718f4a"
      },
      "source": [
        "## Overview <a class=\"anchor\" id=\"overview\"></a>\n",
        "This notebook demonstrates how several Collect Earth Online projects can be:\n",
        "\n",
        "1. Provide functionality to check the structure and validity of user input for modeling; Yet, users are responsible for providing data in good format.\n",
        "2. Re-code the class values and rename the column names.\n",
        "2. Merged into a single dataset that provide a single label for each sample point and an estimate of label uncertainty;\n",
        "3. Split into training, validation, and test (or map reference) samples.\n",
        "\n",
        "The data used in this demonstration are the results of three Collect Earth Online projects that were captured over the Department of Ucayali, Peru. Each project represents the efforts of an individual (or group of individuals working in the same project) to label 1350 points, classifying each into 1 of 4 classes: not oil palm; young oil palm; mature oil palm;  unsure. The datasets preserve all the information from these projects, although user email addresses were anonymized."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e56ab0",
      "metadata": {
        "id": "34e56ab0"
      },
      "source": [
        "## Sample preparation <a class=\"anchor\" id=\"sample-prep\"></a>\n",
        "Load packages, setup configuations, define a helper function..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0968b28e",
      "metadata": {
        "id": "0968b28e",
        "tags": [],
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# from label_utils import load_csv, subset_cols, rename_cols,\\\n",
        "#     check_exclusive, recode, combine_labelers, get_mode_and_occurence\n",
        "\n",
        "#@title (RUN) Setup code\n",
        "## Mount Drive\n",
        "from google.colab import drive\n",
        "root = '/content/gdrive'\n",
        "drive.mount(root)\n",
        "\n",
        "## Clone and/or update VegMapper\n",
        "import os\n",
        "# from datetime import datetime as dt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "repo_path = f\"{root}/MyDrive/repos\"\n",
        "clone_path = 'https://github.com/agroimpacts/VegMapper.git'\n",
        "if not os.path.exists(repo_path):\n",
        "    print(f\"Making {repo_path}\")\n",
        "    os.makedirs(repo_path, exist_ok=True)\n",
        "\n",
        "if not os.path.exists(f\"{repo_path}/VegMapper\"):\n",
        "    !git -C \"{repo_path}\" clone \"{clone_path}\"\n",
        "else:\n",
        "    !git -C \"{repo_path}/VegMapper\" pull\n",
        "\n",
        "os.chdir(f\"{repo_path}/VegMapper\")\n",
        "\n",
        "# Import sample_utils function\n",
        "from vegmapper.calval.label_utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tTlHshUMlrl9",
      "metadata": {
        "id": "tTlHshUMlrl9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# import N survey file(s) into a list (N>=1)\n",
        "fs = [\"calval/data/ceo-survey-user1.csv\",\n",
        "      \"calval/data/ceo-survey-user2.csv\",\n",
        "      \"calval/data/ceo-survey-user3.csv\"]\n",
        "\n",
        "# Set rename dict for renaming column names\n",
        "# {\"old\":\"new\",...}\n",
        "rename_dict = {\"plot_id\":\"Point_ID\",\n",
        "               \"pl_cluster\":\"Clust\",\n",
        "               \"center_lat\":\"Lat\",\n",
        "               \"center_lon\":\"Lon\",\n",
        "               \"Oil Palm?:Young Oil Palm\":\"Young\",\n",
        "               \"Oil Palm?:Mature Oil Palm\":\"Mature\",\n",
        "               \"Oil Palm?:Not Oil Palm\":\"Not\",\n",
        "               \"Oil Palm?:Not Sure\":\"NotSure\"}\n",
        "\n",
        "# Set re-code dict for land cover classes\n",
        "recode_dict = {\"Young\":1,\"Mature\":1,\"Not\":0,\"NotSure\":3}\n",
        "\n",
        "# Set columns to keep:\n",
        "# key_col and label_name are used for joining users's datasets,\n",
        "# columns in useful_col will not participate in joining\n",
        "# and come from the first user instead to avoid repetition.\n",
        "key_col = [\"Point_ID\", \"Clust\"]\n",
        "label_name = \"labeler\"\n",
        "useful_col = [\"Lat\", \"Lon\"]\n",
        "\n",
        "#Set random seed for train/validation/reference split\n",
        "seed = 999"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a6d35cc-fbd0-4468-8e8d-bde402286abc",
      "metadata": {
        "tags": [],
        "id": "5a6d35cc-fbd0-4468-8e8d-bde402286abc"
      },
      "outputs": [],
      "source": [
        "# A helper function to process a csv file\n",
        "def process_csv(csv_path):\n",
        "    \"\"\"\n",
        "    A csv processing pipeline. This function takes a single csv file\n",
        "    and let it pass through a sequence of our pre-defined functions\n",
        "    return: a pandas dataframe of the processed csv.\n",
        "    \"\"\"\n",
        "    print(\"processing: {}\".format(csv_path))\n",
        "    df = load_csv(csv_path)\n",
        "    df = rename_cols(df, rename_dict)\n",
        "    check_exclusive(df, csv_path)\n",
        "\n",
        "    # if you want to combine Young and Mature, just recode both to be 1.\n",
        "    df = recode(df, recode_dict, label_name)\n",
        "\n",
        "    df = subset_cols(df, [*key_col,  *useful_col, label_name])\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88b2fe77-3b6e-4b03-aa71-67529e0993ab",
      "metadata": {
        "id": "88b2fe77-3b6e-4b03-aa71-67529e0993ab"
      },
      "source": [
        "### Read-in, reshape, and recode classes <a class=\"anchor\" id=\"reshape-recode\"></a>\n",
        "The first step was to combine the three datasets into a single dataset, with the columns from each of the three CEO projects, and to recode the four classes into a single column with values 0 (not oil palm),  1 (young oil palm), 2 (mature oil palm), 3 (unsure). At this step, we end up with 3 columns, 1 per completed CEO project: `cl1` = samples from project 1, `cl2` = samples from project 2, `cl3` = samples from project 3. Each column contains the recoded classes (note the renaming of the columns is done in the next code chunk)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88419590-5804-44c2-a251-0cfbcb52a199",
      "metadata": {
        "tags": [],
        "id": "88419590-5804-44c2-a251-0cfbcb52a199"
      },
      "outputs": [],
      "source": [
        "# process ceo-survey-users one by one\n",
        "dats = list(map(process_csv, fs))\n",
        "\n",
        "# combine three datasets into one\n",
        "combined = combine_labelers(dats,by=[\"Point_ID\",\"Clust\"], label_name = label_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c956e090-ed1d-4674-87d2-0dddeb8580dc",
      "metadata": {
        "tags": [],
        "id": "c956e090-ed1d-4674-87d2-0dddeb8580dc"
      },
      "outputs": [],
      "source": [
        "combined"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dbbf0f2",
      "metadata": {
        "id": "8dbbf0f2"
      },
      "source": [
        "### Simplify the classes <a class=\"anchor\" id=\"simplify\"></a>\n",
        "\n",
        "In this step, a single classification is created by finding the modal class for each sample point across the 3 groups' results. This creates a new `class` column, which provides the class from the majority opinion.\n",
        "\n",
        "We repeat this same step again after first collapsing, within each of the `cl1:cl3` columns, the two oil palm classes into a single *oil palm* class with value = 1--*not oil palm* remains 0, and *unsure* remains 3. The modal function was re-run to create a new consensus class, called `class2`. We recommend that `class2` be used for modelling, while `class` may be useful for understanding error patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94baf77b",
      "metadata": {
        "id": "94baf77b"
      },
      "source": [
        "### Calculate sample agreement <a class=\"anchor\" id=\"agreement\"></a>\n",
        "The next step was to calculate some agreement metrics across the three groups' samples. The primary approach was to calculate the proportion of labelling teams that selected the modal class. Since there were just three teams in this example, values were either 0.333, 0.667, 1. This agreement was calculated across for both the original classification scheme (class: 0-3) and the simplifed scheme (), with columns `agree` and `agree2` providing the respective proportions for each observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a845bbb",
      "metadata": {
        "id": "5a845bbb",
        "tags": []
      },
      "outputs": [],
      "source": [
        "combined[['mode', 'mode_agreement']] = combined[\n",
        "    [\"labeler_1\",\"labeler_2\",\"labeler_3\"]\n",
        "].apply(get_mode_and_occurence, axis=1, result_type='expand')\n",
        "pd.set_option('display.max_rows', None)\n",
        "#print(combined)\n",
        "\n",
        "# we can set the mode to -9999 if there is no agreement (mode_freq = 1/num_labelers)\n",
        "combined.loc[combined['mode_agreement'] <= 1/3, 'mode'] = -9999\n",
        "\n",
        "combined = combined.drop(combined[combined['mode'] == -9999].index)\n",
        "print(combined.shape)\n",
        "\n",
        "combined.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6ab33e9",
      "metadata": {
        "id": "c6ab33e9"
      },
      "source": [
        "We can then calculate the average agreement per sample to get a sense of the uncertainty in labels for each class, for all 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3cbab14",
      "metadata": {
        "id": "d3cbab14"
      },
      "outputs": [],
      "source": [
        "agreement = combined.groupby(\"mode\").mean()\n",
        "agreement = agreement.rename(columns={\"mode_agreement\": \"mean agreement\"})\n",
        "print(agreement[['mean agreement']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1ba24d-3edd-42ee-abef-01b3c7ef919c",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "de1ba24d-3edd-42ee-abef-01b3c7ef919c"
      },
      "outputs": [],
      "source": [
        "combined.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b2e124a",
      "metadata": {
        "id": "4b2e124a"
      },
      "source": [
        "And for the reduced set of classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b5b0926",
      "metadata": {
        "id": "5b5b0926"
      },
      "source": [
        "## Split the dataset <a class=\"anchor\" id=\"split\"></a>\n",
        "\n",
        "Here we split the dataset into three parts for model training (60% of the sample), validation (20%), and final assessment (the 20% set aside as the test or map reference dataset).\n",
        "\n",
        "The splits are confined to the usable sample, which is defined as samples not falling into class 3 and those with at least 2/3 observers agreeing on the class. This decision is made based on the simplified sample scheme (class2), rather than the full scheme (class). The resulting splits are denoted in a column called `usage` (this is distinct from the column `use`, which was used to filter out unusable observations).\n",
        "\n",
        "Values of \"unusable\" in the `usage` column indicate observations that were not usable because of their low agreement or uncertain class.  They are included here for completeness, and in case they help with evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1aae09-9860-4c2e-82e8-e1d8c8f3d898",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "5e1aae09-9860-4c2e-82e8-e1d8c8f3d898"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(combined, test_size=0.4, train_size=0.6,\n",
        "                               random_state=seed)\n",
        "\n",
        "val, ref = train_test_split(test, test_size=0.5, train_size=0.5,\n",
        "                            random_state=seed)\n",
        "\n",
        "out = pd.concat(\n",
        "    [train.assign(usage=\"train\"), val.assign(usage=\"validate\"),\n",
        "     ref.assign(usage=\"map_reference/test\")]\n",
        ").reset_index(drop=True)\n",
        "out.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514a3272",
      "metadata": {
        "id": "514a3272"
      },
      "source": [
        "### Combine and export to csv <a class=\"anchor\" id=\"combine\"></a>\n",
        "\n",
        "The ineligible portion of the sample is also added back for completeness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb34864d-3d97-4cf4-b00f-2c6b0c0be69c",
      "metadata": {
        "cellView": "form",
        "id": "bb34864d-3d97-4cf4-b00f-2c6b0c0be69c"
      },
      "outputs": [],
      "source": [
        "#@title (RUN) Export sample\n",
        "gdrive_folder = input(f\"Enter the name of the output folder: \\n\\n\")\n",
        "csv_name = input(f\"Enter the name of the output csv file: \\n\\n\")\n",
        "\n",
        "outpath = f\"{root}/MyDrive/{gdrive_folder}/{csv_name}\"\n",
        "with open(outpath, 'w') as f:\n",
        "    out.to_csv(f, float_format='{:f}'.format, encoding='utf-8',\n",
        "                    index=False)\n",
        "\n",
        "print('file exported')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ab4ddf9",
      "metadata": {
        "id": "7ab4ddf9"
      },
      "source": [
        "And their locations on a map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b00737ac",
      "metadata": {
        "id": "b00737ac"
      },
      "outputs": [],
      "source": [
        "plot_sample = out.copy()\n",
        "\n",
        "usage_dict = {'train': 1, 'validate': 2, \"map_reference/test\": 3, \"unusable\": 4}\n",
        "plot_sample = plot_sample.replace({'usage': usage_dict})\n",
        "\n",
        "print(plot_sample['usage'].unique())\n",
        "\n",
        "rcParams['figure.figsize'] = 10, 10\n",
        "plot_sample.plot.scatter(x='Lon', y='Lat', c='usage', s=12, cmap='viridis')\n",
        "None"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}